---
title: "Supplement to Prediction of Infectious Disease Epidemics via Feature-Weighted Density Ensembles"
author: "Evan L Ray, Nicholas G Reich"
output:
    pdf_document:
        keep_tex: false
        citation_package: natbib
        fig_caption: true
date: "`r format(Sys.time(), '%B %Y')`"
header-includes:
   - \input{GrandMacros.tex}
   - \usepackage{setspace}\onehalfspacing
   - \usepackage{lineno}\linenumbers
   - \usepackage{booktabs}
   - \usepackage{array}
   - \renewcommand{\familydefault}{cmss}
   - \renewcommand{\figurename}{Supplemental Figure}
---

In this supplement, we include additional figures and results.

# Component Model Log Scores and Weighting Features

Supplemental Figs \ref{fig:ComponentModelLogScoresVsWeek}, \ref{fig:ComponentModelLogScoresVsUncertainty}, and \ref{fig:ComponentModelLogScoresVswILI} illustrate the relationship between log scores and weighting features for predictions from the three component models made during the training phase in weeks before the season onset (for predictions of onset timing) or the season peak (for predictions of peak timing or peak incidence).

# Permutation Test Procedure

In the manuscript, we conducted permutation tests to compare mean performance and worst-case performance across


```{r init, include = FALSE}
library(plyr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(grid)
library(awes)
library(nlme)
library(multcomp)
library(doMC)
library(mosaic)

awes_path <- find.package("awes")
```

```{r log_scores_vs_week, echo=FALSE, cache=TRUE, fig.height=8, fig.cap="\\label{fig:ComponentModelLogScoresVsWeek}Log scores achieved by each component model in each week of the season, summarizing across all seasons in both the training phase when all three component models produced predictions.  The thick line is a smoothed estimate of mean log score at each week in the season; the shaded region indicates the convex hull of log scores achieved by each model; and the actual log scores achieved in each week are indicated with points."}
color_palette <- c("#E69F00", "#56B4E9", "#009E73")

regions_to_plot <- c("National", "Region1", "Region7")

log_scores_with_confidence <- bind_rows(
  assemble_stacking_inputs(
    regions = regions_to_plot,
    prediction_target = "onset",
    component_model_names = c("kde", "kcde", "sarima"),
    explanatory_variables = c("analysis_time_season_week",
      "kcde_model_confidence",
      "sarima_model_confidence"),
    include_model_performance = TRUE,
    preds_path = file.path(awes_path, "estimation/loso-predictions")
  ) %>%
    mutate(prediction_target = "onset"),
  assemble_stacking_inputs(
    regions = regions_to_plot,
    prediction_target = "peak_week",
    component_model_names = c("kde", "kcde", "sarima"),
    explanatory_variables = c("analysis_time_season_week",
      "kcde_model_confidence",
      "sarima_model_confidence"),
    include_model_performance = TRUE,
    preds_path = file.path(awes_path, "estimation/loso-predictions")
  ) %>%
    mutate(prediction_target = "peak_week"),
  assemble_stacking_inputs(
    regions = regions_to_plot,
    prediction_target = "peak_inc",
    component_model_names = c("kde", "kcde", "sarima"),
    explanatory_variables = c("analysis_time_season_week",
      "kcde_model_confidence",
      "sarima_model_confidence"),
    include_model_performance = TRUE,
    preds_path = file.path(awes_path, "estimation/loso-predictions")
  ) %>%
    mutate(prediction_target = "peak_inc")
)

log_scores_with_confidence_long <- left_join(
  log_scores_with_confidence %>%
    select_(.dots = c("region", "analysis_time_season", "analysis_time_season_week",
      "prediction_target", "kcde_log_score", "kde_log_score", "sarima_log_score")) %>%
    gather_("model", "log_score",
      c("kcde_log_score", "kde_log_score", "sarima_log_score")) %>%
    mutate(model = substr(model, 1, nchar(model) - 10)),
  log_scores_with_confidence %>%
    select_(.dots = c("region", "analysis_time_season", "analysis_time_season_week",
      "prediction_target",
      "kcde_model_confidence", "kde_model_confidence", "sarima_model_confidence")) %>%
    gather_("model", "model_confidence",
      c("kcde_model_confidence", "kde_model_confidence", "sarima_model_confidence")) %>%
    mutate(model = substr(model, 1, nchar(model) - 17)),
  by = c("region", "analysis_time_season", "analysis_time_season_week",
      "prediction_target", "model")
)

log_scores_with_confidence_long$prediction_target[log_scores_with_confidence_long$prediction_target == "onset"] <- "Onset Timing"
log_scores_with_confidence_long$prediction_target[log_scores_with_confidence_long$prediction_target == "peak_inc"] <- "Peak Incidence"
log_scores_with_confidence_long$prediction_target[log_scores_with_confidence_long$prediction_target == "peak_week"] <- "Peak Timing"
log_scores_with_confidence_long$prediction_target <- factor(log_scores_with_confidence_long$prediction_target,
  levels = c("Onset Timing", "Peak Timing", "Peak Incidence"))

summarized_log_scores <- log_scores_with_confidence_long %>%
  filter(analysis_time_season %in% paste0(1999:2015, "/", 2000:2016)) %>%
  group_by(model, region, prediction_target, analysis_time_season_week) %>%
  summarize(
    mean_log_score = mean(log_score),
    min_log_score = min(log_score),
    max_log_score = max(log_score)) %>%
  mutate(Model = toupper(model))
summarized_log_scores$smoothed_log_score <- NA
summarized_log_scores$smoothed_max_log_score <- NA
summarized_log_scores$smoothed_min_log_score <- NA
for(region_val in unique(summarized_log_scores$region)) {
  for(model_val in unique(summarized_log_scores$model)) {
    for(prediction_target_val in unique(summarized_log_scores$prediction_target)) {
      if(identical(prediction_target_val, "Peak Incidence")) {
        loess_span <- 0.5
      } else {
        loess_span <- 0.75
      }
      inds <- (summarized_log_scores$region == region_val &
        summarized_log_scores$model == model_val &
        summarized_log_scores$prediction_target == prediction_target_val)
      if(sum(inds) == 1 || model_val == "kde") {
        summarized_log_scores$smoothed_log_score[inds] <-
          summarized_log_scores$mean_log_score[inds]
        summarized_log_scores$smoothed_max_log_score[inds] <-
          summarized_log_scores$max_log_score[inds]
        summarized_log_scores$smoothed_min_log_score[inds] <-
          summarized_log_scores$min_log_score[inds]
      } else {
        summarized_log_scores$smoothed_log_score[inds] <-
          suppressWarnings(predict(
            suppressWarnings(
              loess(log_score ~ analysis_time_season_week, data = log_scores_with_confidence_long %>%
                filter(analysis_time_season %in% paste0(1999:2015, "/", 2000:2016) &
                  region == region_val &
                  model == model_val &
                  prediction_target == prediction_target_val),
                span = loess_span
                )
              ),
            newdata = summarized_log_scores[inds, ]
        ))
        summarized_log_scores$smoothed_max_log_score[inds] <-
          suppressWarnings(predict(
            suppressWarnings(
              loess(max_log_score ~ analysis_time_season_week, data = summarized_log_scores[inds, ],
                span = loess_span))
            ))
        summarized_log_scores$smoothed_min_log_score[inds] <-
          suppressWarnings(predict(
            suppressWarnings(
              loess(min_log_score ~ analysis_time_season_week, data = summarized_log_scores[inds, ],
                span = loess_span))
          ))
      }
    }
  }
}
summarized_log_scores$prediction_target[summarized_log_scores$prediction_target == "onset"] <- "Onset Timing"
summarized_log_scores$prediction_target[summarized_log_scores$prediction_target == "peak_inc"] <- "Peak Incidence"
summarized_log_scores$prediction_target[summarized_log_scores$prediction_target == "peak_week"] <- "Peak Timing"
summarized_log_scores$prediction_target <- factor(summarized_log_scores$prediction_target,
  levels = c("Onset Timing", "Peak Timing", "Peak Incidence"))

log_scores_with_confidence_long <-
  log_scores_with_confidence_long  %>%
  mutate(Model = toupper(model))

regions_to_plot <- c("National", "Region 1", "Region 7")

StatChull <- ggproto("StatChull", Stat,
  compute_group = function(data, scales) {
    data[chull(data$x, data$y), , drop = FALSE]
  },

  required_aes = c("x", "y")
)

stat_chull <- function(mapping = NULL, data = NULL, geom = "polygon",
                       position = "identity", na.rm = FALSE, show.legend = NA,
                       inherit.aes = TRUE, ...) {
  ggplot2::layer(
    stat = StatChull, data = data, mapping = mapping, geom = geom,
    position = position, show.legend = show.legend, inherit.aes = inherit.aes,
    params = list(na.rm = na.rm, ...)
  )
}


ggplot() +
  stat_chull(
    aes(x = analysis_time_season_week, y = log_score,
      colour = Model,
      fill = Model,
      linetype = Model),
    alpha = 0.2,
    data = log_scores_with_confidence_long[log_scores_with_confidence_long$region %in% regions_to_plot, ]) +
  geom_line(
    aes(x = analysis_time_season_week,
      y = smoothed_log_score,
      colour = Model,
      linetype = Model),
    size = 1.5,
    data = summarized_log_scores[summarized_log_scores$region %in% regions_to_plot, ]) +
  geom_point(aes(x = analysis_time_season_week, y = log_score, colour = Model, shape = Model),
    alpha = 0.25,
    position = position_jitter(),
    data = log_scores_with_confidence_long[log_scores_with_confidence_long$region %in% regions_to_plot, ]) +
  scale_colour_manual(values = color_palette) +
  facet_grid(region ~ prediction_target, scales = "free_x") +
  xlab("Season Week at Analysis Time") +
  ylab("Log Score") +
  ggtitle("Log Scores vs. Season Week at Analysis Time") +
  theme_bw()
```


```{r log_scores_vs_uncertainty, echo=FALSE, cache=TRUE, fig.height=8, fig.cap="\\label{fig:ComponentModelLogScoresVsUncertainty}Log scores achieved by each component model vs. model uncertainty as measured by the number of bins required to cover 90% of the predictive distribution.  The plot summarizes results across all seasons in the training phase when all three component models produced predictions.  The thick line is a smoothed estimate of mean log score at each value of model uncertainty; the shaded region indicates the convex hull of log scores achieved by each model; and the actual log scores achieved in each week are indicated with points.  The KCDE and SARIMA models condition on all previously observed data within the current season, and generally have high certainly when the target event (season onset or season peak) has almost occurred or has already occurred."}
color_palette <- c("#E69F00", "#56B4E9", "#009E73")

regions_to_plot <- c("National", "Region1", "Region7")

log_scores_with_confidence <- bind_rows(
  assemble_stacking_inputs(
    regions = regions_to_plot,
    prediction_target = "onset",
    component_model_names = c("kde", "kcde", "sarima"),
    explanatory_variables = c("analysis_time_season_week",
      "kcde_model_confidence",
      "sarima_model_confidence"),
    include_model_performance = TRUE,
    preds_path = file.path(awes_path, "estimation/loso-predictions")
  ) %>%
    mutate(prediction_target = "onset"),
  assemble_stacking_inputs(
    regions = regions_to_plot,
    prediction_target = "peak_week",
    component_model_names = c("kde", "kcde", "sarima"),
    explanatory_variables = c("analysis_time_season_week",
      "kcde_model_confidence",
      "sarima_model_confidence"),
    include_model_performance = TRUE,
    preds_path = file.path(awes_path, "estimation/loso-predictions")
  ) %>%
    mutate(prediction_target = "peak_week"),
  assemble_stacking_inputs(
    regions = regions_to_plot,
    prediction_target = "peak_inc",
    component_model_names = c("kde", "kcde", "sarima"),
    explanatory_variables = c("analysis_time_season_week",
      "kcde_model_confidence",
      "sarima_model_confidence"),
    include_model_performance = TRUE,
    preds_path = file.path(awes_path, "estimation/loso-predictions")
  ) %>%
    mutate(prediction_target = "peak_inc")
)

log_scores_with_confidence_long <- left_join(
  log_scores_with_confidence %>%
    select_(.dots = c("region", "analysis_time_season", "analysis_time_season_week",
      "prediction_target", "kcde_log_score", "kde_log_score", "sarima_log_score")) %>%
    gather_("model", "log_score",
      c("kcde_log_score", "kde_log_score", "sarima_log_score")) %>%
    mutate(model = substr(model, 1, nchar(model) - 10)),
  log_scores_with_confidence %>%
    select_(.dots = c("region", "analysis_time_season", "analysis_time_season_week",
      "prediction_target",
      "kcde_model_confidence", "kde_model_confidence", "sarima_model_confidence")) %>%
    gather_("model", "model_confidence",
      c("kcde_model_confidence", "kde_model_confidence", "sarima_model_confidence")) %>%
    mutate(model = substr(model, 1, nchar(model) - 17)),
  by = c("region", "analysis_time_season", "analysis_time_season_week",
      "prediction_target", "model")
)

log_scores_with_confidence_long$prediction_target[log_scores_with_confidence_long$prediction_target == "onset"] <- "Onset Timing"
log_scores_with_confidence_long$prediction_target[log_scores_with_confidence_long$prediction_target == "peak_inc"] <- "Peak Incidence"
log_scores_with_confidence_long$prediction_target[log_scores_with_confidence_long$prediction_target == "peak_week"] <- "Peak Timing"
log_scores_with_confidence_long$prediction_target <- factor(log_scores_with_confidence_long$prediction_target,
  levels = c("Onset Timing", "Peak Timing", "Peak Incidence"))

summarized_log_scores <- log_scores_with_confidence_long %>%
  filter(analysis_time_season %in% paste0(1999:2015, "/", 2000:2016)) %>%
  group_by(model, region, prediction_target, model_confidence) %>%
  summarize(
    mean_log_score = mean(log_score),
    min_log_score = min(log_score),
    max_log_score = max(log_score)) %>%
  mutate(Model = toupper(model))
summarized_log_scores$smoothed_log_score <- NA
summarized_log_scores$smoothed_max_log_score <- NA
summarized_log_scores$smoothed_min_log_score <- NA
for(region_val in unique(summarized_log_scores$region)) {
  for(model_val in unique(summarized_log_scores$model)) {
    for(prediction_target_val in unique(summarized_log_scores$prediction_target)) {
      if(identical(prediction_target_val, "Peak Incidence")) {
        loess_span <- 0.5
      } else {
        loess_span <- 0.75
      }
      inds <- (summarized_log_scores$region == region_val &
        summarized_log_scores$model == model_val &
        summarized_log_scores$prediction_target == prediction_target_val)
      if(sum(inds) == 1 || model_val == "kde") {
        summarized_log_scores$smoothed_log_score[inds] <-
          summarized_log_scores$mean_log_score[inds]
        summarized_log_scores$smoothed_max_log_score[inds] <-
          summarized_log_scores$max_log_score[inds]
        summarized_log_scores$smoothed_min_log_score[inds] <-
          summarized_log_scores$min_log_score[inds]
      } else {
        summarized_log_scores$smoothed_log_score[inds] <-
          suppressWarnings(predict(
            suppressWarnings(
              loess(log_score ~ model_confidence, data = log_scores_with_confidence_long %>%
                filter(analysis_time_season %in% paste0(1999:2015, "/", 2000:2016) &
                  region == region_val &
                  model == model_val &
                  prediction_target == prediction_target_val),
                span = loess_span
                )
              ),
            newdata = summarized_log_scores[inds, ]
        ))
        summarized_log_scores$smoothed_max_log_score[inds] <-
          suppressWarnings(predict(
            suppressWarnings(
              loess(max_log_score ~ model_confidence, data = summarized_log_scores[inds, ],
                span = loess_span))
            ))
        summarized_log_scores$smoothed_min_log_score[inds] <-
          suppressWarnings(predict(
            suppressWarnings(
              loess(min_log_score ~ model_confidence, data = summarized_log_scores[inds, ],
                span = loess_span))
          ))
      }
    }
  }
}
summarized_log_scores$prediction_target[summarized_log_scores$prediction_target == "onset"] <- "Onset Timing"
summarized_log_scores$prediction_target[summarized_log_scores$prediction_target == "peak_inc"] <- "Peak Incidence"
summarized_log_scores$prediction_target[summarized_log_scores$prediction_target == "peak_week"] <- "Peak Timing"
summarized_log_scores$prediction_target <- factor(summarized_log_scores$prediction_target,
  levels = c("Onset Timing", "Peak Timing", "Peak Incidence"))

log_scores_with_confidence_long <-
  log_scores_with_confidence_long  %>%
  mutate(Model = toupper(model))

regions_to_plot <- c("National", "Region 1", "Region 7")

ggplot() +
  stat_chull(
    aes(x = model_confidence, y = log_score,
      colour = Model,
      fill = Model,
      linetype = Model),
    alpha = 0.2,
    data = log_scores_with_confidence_long[log_scores_with_confidence_long$region %in% regions_to_plot, ]) +
  geom_line(
    aes(x = model_confidence,
      y = smoothed_log_score,
      colour = Model,
      linetype = Model),
    size = 1.5,
    data = summarized_log_scores[summarized_log_scores$region %in% regions_to_plot, ]) +
  geom_point(aes(x = model_confidence, y = log_score, colour = Model, shape = Model),
    alpha = 0.25,
    position = position_jitter(),
    data = log_scores_with_confidence_long[log_scores_with_confidence_long$region %in% regions_to_plot, ]) +
  scale_colour_manual(values = color_palette) +
  facet_grid(region ~ prediction_target, scales = "free_x") +
  xlab("Model Uncertainty") +
  ylab("Log Score") +
  ggtitle("Log Scores vs. Model Uncertainty") +
  theme_bw()
```


```{r log_scores_vs_wili, echo=FALSE, cache=TRUE, fig.height=8, fig.cap="\\label{fig:ComponentModelLogScoresVswILI}Log scores achieved by each component model vs. wILI in the week of the season when predictions were made.  The plot summarizes results across all seasons in the training phase when all three component models produced predictions.  The thick line is a smoothed estimate of mean log score at each week in the season; the shaded region indicates the convex hull of log scores achieved by each model; and the actual log scores achieved in each week are indicated with points."}
color_palette <- c("#E69F00", "#56B4E9", "#009E73")

regions_to_plot <- c("National", "Region1", "Region7")

log_scores_with_confidence <- bind_rows(
  assemble_stacking_inputs(
    regions = regions_to_plot,
    prediction_target = "onset",
    component_model_names = c("kde", "kcde", "sarima"),
    explanatory_variables = c("analysis_time_season_week",
      "kcde_model_confidence",
      "sarima_model_confidence",
      "weighted_ili"),
    include_model_performance = TRUE,
    preds_path = file.path(awes_path, "estimation/loso-predictions")
  ) %>%
    mutate(prediction_target = "onset"),
  assemble_stacking_inputs(
    regions = regions_to_plot,
    prediction_target = "peak_week",
    component_model_names = c("kde", "kcde", "sarima"),
    explanatory_variables = c("analysis_time_season_week",
      "kcde_model_confidence",
      "sarima_model_confidence",
      "weighted_ili"),
    include_model_performance = TRUE,
    preds_path = file.path(awes_path, "estimation/loso-predictions")
  ) %>%
    mutate(prediction_target = "peak_week"),
  assemble_stacking_inputs(
    regions = regions_to_plot,
    prediction_target = "peak_inc",
    component_model_names = c("kde", "kcde", "sarima"),
    explanatory_variables = c("analysis_time_season_week",
      "kcde_model_confidence",
      "sarima_model_confidence",
      "weighted_ili"),
    include_model_performance = TRUE,
    preds_path = file.path(awes_path, "estimation/loso-predictions")
  ) %>%
    mutate(prediction_target = "peak_inc")
)

log_scores_with_confidence_long <-
  log_scores_with_confidence %>%
    select_(.dots = c("region", "analysis_time_season", "analysis_time_season_week", "weighted_ili",
      "prediction_target", "kcde_log_score", "kde_log_score", "sarima_log_score")) %>%
    gather_("model", "log_score",
      c("kcde_log_score", "kde_log_score", "sarima_log_score")) %>%
    mutate(model = substr(model, 1, nchar(model) - 10))

log_scores_with_confidence_long$prediction_target[log_scores_with_confidence_long$prediction_target == "onset"] <- "Onset Timing"
log_scores_with_confidence_long$prediction_target[log_scores_with_confidence_long$prediction_target == "peak_inc"] <- "Peak Incidence"
log_scores_with_confidence_long$prediction_target[log_scores_with_confidence_long$prediction_target == "peak_week"] <- "Peak Timing"
log_scores_with_confidence_long$prediction_target <- factor(log_scores_with_confidence_long$prediction_target,
  levels = c("Onset Timing", "Peak Timing", "Peak Incidence"))

summarized_log_scores <- log_scores_with_confidence_long %>%
  filter(analysis_time_season %in% paste0(1999:2015, "/", 2000:2016)) %>%
  group_by(model, region, prediction_target, weighted_ili) %>%
  summarize(
    mean_log_score = mean(log_score),
    min_log_score = min(log_score),
    max_log_score = max(log_score)) %>%
  mutate(Model = toupper(model))
summarized_log_scores$smoothed_log_score <- NA
summarized_log_scores$smoothed_max_log_score <- NA
summarized_log_scores$smoothed_min_log_score <- NA
for(region_val in unique(summarized_log_scores$region)) {
  for(model_val in unique(summarized_log_scores$model)) {
    for(prediction_target_val in unique(summarized_log_scores$prediction_target)) {
      if(identical(prediction_target_val, "Peak Incidence")) {
        loess_span <- 0.75
      } else {
        loess_span <- 0.45
      }
      inds <- (summarized_log_scores$region == region_val &
        summarized_log_scores$model == model_val &
        summarized_log_scores$prediction_target == prediction_target_val)
      if(sum(inds) == 1 || model_val == "kde") {
        summarized_log_scores$smoothed_log_score[inds] <-
          summarized_log_scores$mean_log_score[inds]
        summarized_log_scores$smoothed_max_log_score[inds] <-
          summarized_log_scores$max_log_score[inds]
        summarized_log_scores$smoothed_min_log_score[inds] <-
          summarized_log_scores$min_log_score[inds]
      } else {
        summarized_log_scores$smoothed_log_score[inds] <-
          suppressWarnings(predict(
            suppressWarnings(
              loess(log_score ~ weighted_ili, data = log_scores_with_confidence_long %>%
                filter(analysis_time_season %in% paste0(1999:2015, "/", 2000:2016) &
                  region == region_val &
                  model == model_val &
                  prediction_target == prediction_target_val),
                span = loess_span
                )
              ),
            newdata = summarized_log_scores[inds, ]
        ))
        summarized_log_scores$smoothed_max_log_score[inds] <-
          suppressWarnings(predict(
            suppressWarnings(
              loess(max_log_score ~ weighted_ili, data = summarized_log_scores[inds, ],
                span = loess_span))
            ))
        summarized_log_scores$smoothed_min_log_score[inds] <-
          suppressWarnings(predict(
            suppressWarnings(
              loess(min_log_score ~ weighted_ili, data = summarized_log_scores[inds, ],
                span = loess_span))
          ))
      }
    }
  }
}
summarized_log_scores$prediction_target[summarized_log_scores$prediction_target == "onset"] <- "Onset Timing"
summarized_log_scores$prediction_target[summarized_log_scores$prediction_target == "peak_inc"] <- "Peak Incidence"
summarized_log_scores$prediction_target[summarized_log_scores$prediction_target == "peak_week"] <- "Peak Timing"
summarized_log_scores$prediction_target <- factor(summarized_log_scores$prediction_target,
  levels = c("Onset Timing", "Peak Timing", "Peak Incidence"))

log_scores_with_confidence_long <-
  log_scores_with_confidence_long  %>%
  mutate(Model = toupper(model))

regions_to_plot <- c("National", "Region 1", "Region 7")


ggplot() +
  stat_chull(
    aes(x = weighted_ili, y = log_score,
      colour = Model,
      fill = Model,
      linetype = Model),
    alpha = 0.2,
    data = log_scores_with_confidence_long[log_scores_with_confidence_long$region %in% regions_to_plot, ]) +
  geom_line(
    aes(x = weighted_ili,
      y = smoothed_log_score,
      colour = Model,
      linetype = Model),
    size = 1.5,
    data = summarized_log_scores[summarized_log_scores$region %in% regions_to_plot, ]) +
  geom_point(aes(x = weighted_ili, y = log_score, colour = Model, shape = Model),
    alpha = 0.25,
    position = position_jitter(),
    data = log_scores_with_confidence_long[log_scores_with_confidence_long$region %in% regions_to_plot, ]) +
  scale_colour_manual(values = color_palette) +
  facet_grid(region ~ prediction_target, scales = "free_x") +
  xlab("wILI") +
  ylab("Log Score") +
  ggtitle("Log Scores vs. wILI") +
  theme_bw()
```

```{r fw_reg_wu_model_weights, echo=FALSE, cache=TRUE, fig.height=8, fig.cap="\\label{fig:FWregwuModelWeights}Weights assigned to each component model by the FW-reg-wu model for the prediction of season peak incidence at the national level. There are three weighting functions (one for each component model) represented in each row of the figure. The value of the weight is depicted by the color. Each function depends on three features: the week of the season at the time when the predictions are made, KCDE model uncertainty, and SARIMA model uncertainty. Model uncertainty represents the minimum number of predictive distribution bins required to cover 90% probability of the predictive distribution, so the higher this number is the more uncertain the model is."}
get_legend_grob <- function(x) {
  data <- ggplot2:::ggplot_build(x)

  plot <- data$plot
  panel <- data$panel
  data <- data$data
  theme <- ggplot2:::plot_theme(plot)
  position <- theme$legend.position
  if (length(position) == 2) {
    position <- "manual"
  }

  legend_box <- if (position != "none") {
    ggplot2:::build_guides(plot$scales, plot$layers, plot$mapping,
      position, theme, plot$guides, plot$labels)
  } else {
    ggplot2:::zeroGrob()
  }
  if (ggplot2:::is.zero(legend_box)) {
    position <- "none"
  }
  else {
    legend_width <- gtable:::gtable_width(legend_box) + theme$legend.margin
    legend_height <- gtable:::gtable_height(legend_box) + theme$legend.margin
    just <- valid.just(theme$legend.justification)
    xjust <- just[1]
    yjust <- just[2]
    if (position == "manual") {
      xpos <- theme$legend.position[1]
      ypos <- theme$legend.position[2]
      legend_box <- editGrob(legend_box, vp = viewport(x = xpos,
        y = ypos, just = c(xjust, yjust), height = legend_height,
        width = legend_width))
    }
    else {
      legend_box <- editGrob(legend_box, vp = viewport(x = xjust,
        y = yjust, just = c(xjust, yjust)))
    }
  }
  return(legend_box)
}

awes_path <- find.package("awes")
loso_preds_path <- file.path(awes_path, "estimation/loso-predictions")
stacking_model_fits_path <- file.path(awes_path, "estimation/xgb-stacking/fits")

component_model_names <- c("kde", "kcde", "sarima")
region <- "National"
prediction_target <- "peak_inc"
explanatory_variables <- "analysis_time_season_week-kcde_model_confidence-sarima_model_confidence"
explanatory_variables_split <- strsplit(explanatory_variables, "-")[[1]]
ensemble_model_name <- "xgb_stacking_reg_wu"

weights <- readRDS(
  file = file.path(stacking_model_fits_path,
    paste0("model_weights_", region, "_", prediction_target, "_", explanatory_variables, ".rds"))) %>%
  select_(.dots = c(explanatory_variables_split, paste0(component_model_names, "_log_score_params_combined"))) %>%
  `colnames<-`(c(explanatory_variables_split, component_model_names)) %>%
  mutate(region = region,
    prediction_target = prediction_target)

weights <- weights %>%
  gather_("model", "weight", c("kde", "kcde", "sarima"))

typical_season_week <- 17L
if(prediction_target %in% c("onset", "peak_week")) {
  typical_confidence <- 5L
} else {
  typical_confidence <- 20L
}

p1 <- ggplot(
  weights %>%
    filter(sarima_model_confidence == typical_confidence &
        kcde_model_confidence %% 2 == 1) %>%
    mutate(model = toupper(model))) +
  geom_raster(aes(x = analysis_time_season_week, y = kcde_model_confidence, fill = weight)) +
  scale_fill_gradient2("Model\nWeight",
    breaks = c(0, 0.25, 0.5, 0.75, 1),
    labels = as.character(c(0, 0.25, 0.5, 0.75, 1)),
    low = "#b2182b",
    mid = "#f7f7f7",
    high = "#2166ac",
    midpoint = 0.5) +
  facet_wrap(~ model, nrow = 1L) +
  xlab("Season Week at Analysis Time") +
  ylab("KCDE Model Uncertainty") +
  theme_bw()

plot_legend <- get_legend_grob(p1)

p1 <- p1 + theme(legend.position = "none")

p2 <- ggplot(
  weights %>%
    filter(kcde_model_confidence == typical_confidence &
        sarima_model_confidence %% 2 == 1) %>%
    mutate(model = toupper(model))) +
  geom_raster(aes(x = analysis_time_season_week, y = sarima_model_confidence, fill = weight)) +
  scale_fill_gradient2("Model\nWeight",
    breaks = c(0, 0.25, 0.5, 0.75, 1),
    labels = as.character(c(0, 0.25, 0.5, 0.75, 1)),
    low = "#b2182b",
    mid = "#f7f7f7",
    high = "#2166ac",
    midpoint = 0.5) +
  facet_wrap(~ model, nrow = 1L) +
  xlab("Season Week at Analysis Time") +
  ylab("SARIMA Model Uncertainty") +
  theme_bw() +
  theme(legend.position = "none")

p3 <- ggplot(
  weights %>%
    filter(
      analysis_time_season_week == typical_season_week &
      kcde_model_confidence %%2 == 1 &
      sarima_model_confidence %% 2 == 1) %>%
    mutate(model = toupper(model))) +
  geom_raster(aes(x = kcde_model_confidence, y = sarima_model_confidence, fill = weight)) +
  scale_fill_gradient2("Model\nWeight",
    breaks = c(0, 0.25, 0.5, 0.75, 1),
    labels = as.character(c(0, 0.25, 0.5, 0.75, 1)),
    low = "#b2182b",
    mid = "#f7f7f7",
    high = "#2166ac",
    midpoint = 0.5) +
  facet_wrap(~ model, nrow = 1L) +
  xlab("KCDE Model Uncertainty") +
  ylab("SARIMA Model Uncertainty") +
  theme_bw() +
  theme(legend.position = "none")


grid.newpage()
num_lines_text <- 1
pushViewport(viewport(layout =
    grid.layout(nrow = 6, ncol = 2,
      heights = unit(
        c(num_lines_text, 1, num_lines_text, 1, num_lines_text, 1),
        rep(c("lines", "null"), 3)),
      widths = unit(c(4, 1), c("null", "null")))))
grid.text("A: SARIMA Model Uncertainty Fixed at 20",
  x = unit(0, "npc"),
  just = "left",
  gp = gpar(fontsize = 12),
  vp = viewport(layout.pos.row = 1, layout.pos.col = 1:2))
grid.text("B: KCDE Model Uncertainty Fixed at 20",
  x = unit(0, "npc"),
  just = "left",
  gp = gpar(fontsize = 12),
  vp = viewport(layout.pos.row = 3, layout.pos.col = 1:2))
grid.text("C: Season Week Fixed at 17",
  x = unit(0, "npc"),
  just = "left",
  gp = gpar(fontsize = 12),
  vp = viewport(layout.pos.row = 5, layout.pos.col = 1:2))

print(p1, vp = viewport(layout.pos.row = 2, layout.pos.col = 1))
print(p2, vp = viewport(layout.pos.row = 4, layout.pos.col = 1))
print(p3, vp = viewport(layout.pos.row = 6, layout.pos.col = 1))

pushViewport(viewport(layout.pos.row = 3:4, layout.pos.col = 2))
grid.draw(plot_legend)
upViewport()
```


```{r test_phase_log_scores_summary_v2, echo=FALSE, eval=FALSE, fig.height=8, fig.cap="\\label{fig:performance-model-means}Point estimates and confidence intervals for mean log score for each model in weeks before the target (onset or peak) occurred.  Estimates are obtained from a mixed effects model with a separate fixed effect mean for the interaction of model and prediction target; random effects for each combination of region, season, model, and prediction target; and lag 1 autocorrelation nested within each combination of region, season, model, and prediction target.  The wider confidence interval bounds are simultaneous confidence intervals with an approximate familywise 95% coverage rate for all intervals.  The inner confidence intervals are calculated separately, with approximate coverage rates of 95%.  Log scores of -Infinity were truncated at -10 before fitting this model."}
awes_path <- find.package("awes")

region_season_obs_quantities <- flu_data %>%
  select_(.dots = c("region", "season")) %>%
  distinct() %>%
  filter(season %in% paste0(2011:2015, "/", 2012:2016)) %>%
  mutate(
    observed_onset_week = NA,
    observed_peak_week = NA
  )

for(rs_row in seq_len(nrow(region_season_obs_quantities))) {
  temp <- get_observed_seasonal_quantities(
    data = flu_data[flu_data$region == region_season_obs_quantities$region[rs_row], , drop = FALSE],
    season = region_season_obs_quantities$season[rs_row],
    first_CDC_season_week = 10,
    last_CDC_season_week = 42,
    onset_baseline =
      get_onset_baseline(region = region_season_obs_quantities$region[rs_row],
        season = region_season_obs_quantities$season[rs_row]),
    incidence_var = "weighted_ili",
    incidence_bins = data.frame(
      lower = c(0, seq(from = 0.05, to = 12.95, by = 0.1)),
      upper = c(seq(from = 0.05, to = 12.95, by = 0.1), Inf)),
    incidence_bin_names = as.character(seq(from = 0, to = 13, by = 0.1))
  )

  region_season_obs_quantities$observed_onset_week[rs_row] <-
    temp$observed_onset_week
  region_season_obs_quantities$observed_peak_week[rs_row] <-
    temp$observed_peak_week[1]
}

region_season_obs_quantities$observed_onset_week[
  region_season_obs_quantities$observed_onset_week == "none"] <- 42
region_season_obs_quantities <- region_season_obs_quantities %>%
  transmute(
    region = gsub(" ", "", region),
    analysis_time_season = season,
    observed_onset_week = as.numeric(observed_onset_week),
    observed_peak_week = observed_peak_week
  )
region_season_obs_quantities$region[region_season_obs_quantities$region == "X"] <- "National"

all_models <- c("kde", "kcde", "sarima", "equal_weights", "em_stacking", "xgb_stacking_unregularized", "xgb_stacking_reg_w", "xgb_stacking_reg_wu", "xgb_stacking_reg_wui")
all_targets <- c("onset", "peak_week", "peak_inc")
preds <- assemble_predictions(
  preds_path = file.path(awes_path, "evaluation/test-predictions"),
  models = all_models,
  prediction_targets = all_targets,
  prediction_types = "log_score"
) %>%
  filter(analysis_time_season_week %in% 10:40) %>%
  gather_("prediction_target", "log_score",
    c("onset_log_score", "peak_week_log_score", "peak_inc_log_score")) %>%
  mutate(
    prediction_target = substr(prediction_target, 1, nchar(prediction_target) - 10),
    model = factor(model, levels = all_models),
    score = exp(log_score)
  )
preds$log_score[is.infinite(preds$log_score)] <- -10
preds <- preds %>%
  left_join(region_season_obs_quantities, by = c("region", "analysis_time_season")) %>%
  mutate(
    before_onset = (analysis_time_season_week < observed_onset_week),
    before_peak = (analysis_time_season_week < observed_peak_week))
preds$before_target_date <- ifelse(
  preds$prediction_target == "onset",
  c("on or after\ntarget date", "before\ntarget date")[preds$before_onset + 1],
  c("on or after\ntarget date", "before\ntarget date")[preds$before_peak + 1]
)

unique_region_season_model_autocor <- preds %>%
  filter(before_target_date == "before\ntarget date") %>%
  select_("region", "analysis_time_season", "model", "prediction_target", "log_score") %>%
  group_by_("region", "analysis_time_season", "model", "prediction_target") %>%
  summarize(
    log_score_autocor = acf(log_score, plot = FALSE)[["acf"]][2, 1, 1]
  )
## set to 1 for kde
unique_region_season_model_autocor$log_score_autocor[
  is.na(unique_region_season_model_autocor$log_score_autocor)] <- 1

preds <- preds %>%
  mutate(
    region = factor(region),
    analysis_time_season = factor(analysis_time_season),
    model = factor(model),
    prediction_target = factor(prediction_target),
    unique_region_season_model_target = factor(
      paste(region, analysis_time_season, model, prediction_target, sep = "_")
    )
  )
results_fit_before_target <- lme(log_score ~ model * prediction_target,
  random = ~ 1 | unique_region_season_model_target,
  correlation = corAR1(
    value = mean(unique_region_season_model_autocor$log_score_autocor),
    form = ~ analysis_time_season_week | unique_region_season_model_target),
  method = "REML",
  data = preds[preds$before_target_date == "before\ntarget date", ])

num_models <- length(all_models)
num_targets <- length(all_targets)

unique_model_descriptors <- paste0("model", all_models)
unique_target_descriptors <- paste0("prediction_target", all_targets)

lc_df <- expand.grid(
  model = all_models,
  target = all_targets,
  stringsAsFactors = FALSE)

lc_df$model_descriptor <- paste0("model", lc_df$model)
lc_df$target_descriptor <- paste0("prediction_target", lc_df$target)
lc_df$name <- apply(as.matrix(lc_df[, 1:2]), 1, paste, collapse = "-")

num_leading_cols <- ncol(lc_df)
coef_cols <- seq(
  from = num_leading_cols + 1,
  length = num_models * num_targets
)

# corresponding indicator vector for each coefficient
coef_names <- names(fixef(results_fit_before_target))
unique_coef_name_component_descriptors <- unique(unlist(strsplit(coef_names, ":")))
intercept_model <- unique_model_descriptors[
  !(unique_model_descriptors %in% unique_coef_name_component_descriptors)]
intercept_target <- unique_target_descriptors[
  !(unique_target_descriptors %in% unique_coef_name_component_descriptors)]
for(coef_ind in seq(from = 1, to = length(coef_names))) {
	split_name <- unlist(strsplit(coef_names[[coef_ind]], ":"))
	if(!any(split_name %in% unique_model_descriptors[unique_model_descriptors != intercept_model])) {
		split_name <- c(split_name, unique_model_descriptors)
	}
	if(!any(split_name %in% unique_target_descriptors[unique_target_descriptors != intercept_target])) {
		split_name <- c(split_name, unique_target_descriptors)
	}

	lc_df[[paste0("coef", coef_ind)]] <- 0
	lc_df[[paste0("coef", coef_ind)]][
	  lc_df$model_descriptor %in% split_name &
		lc_df$target_descriptor %in% split_name] <- 1
}

model_row_inds <- seq_len(nrow(lc_df))

# ## contrasts of (mean performance model 1) - (mean performance model 2) for all model pairs
rowind <- nrow(lc_df)
for(prediction_target in all_targets) {
  for(fit_method1_ind in seq_len(length(all_models) - 1)) {
    for(fit_method2_ind in seq(from = fit_method1_ind + 1, to = length(all_models))) {
      rowind <- rowind + 1

      m1_name <- all_models[fit_method1_ind]
      m2_name <- all_models[fit_method2_ind]

      m1_rowind <- which(lc_df$name == paste(m1_name, prediction_target, sep = "-"))
      m2_rowind <- which(lc_df$name == paste(m2_name, prediction_target, sep = "-"))

     	lc_df[rowind, ] <- rep(NA, ncol(lc_df))
      lc_df$name[rowind] <- paste0(m1_name, "-", m2_name, "-", prediction_target)
     	lc_df$target[rowind] <- prediction_target
     	lc_df[rowind, coef_cols] <- lc_df[m1_rowind, coef_cols] - lc_df[m2_rowind, coef_cols]
    }
  }
}

contrast_row_inds <- seq(from = length(model_row_inds) + 1, to = nrow(lc_df))

lc_df$name <- factor(lc_df$name, levels = lc_df$name)

K_mat <- as.matrix(lc_df[, coef_cols])

# get point estimates
lc_df$pt_est <- as.vector(K_mat %*% matrix(fixef(results_fit_before_target)))

# get familywise CIs
confint_rows <- seq_len(nrow(lc_df))
lc_df$fam_CI_lb <- NA
lc_df$fam_CI_ub <- NA
fam_CI_obj <- glht(results_fit_before_target, linfct = K_mat[confint_rows, ])
temp <- confint(fam_CI_obj)$confint
lc_df$fam_CI_lb[confint_rows] <- temp[, 2]
lc_df$fam_CI_ub[confint_rows] <- temp[, 3]

# get individual CIs
lc_df$ind_CI_lb <- NA
lc_df$ind_CI_ub <- NA
for(rowind in confint_rows) {
	ind_CI_obj <- glht(results_fit_before_target, linfct = K_mat[rowind, , drop = FALSE])
	temp <- confint(ind_CI_obj)$confint
	lc_df$ind_CI_lb[rowind] <- temp[, 2]
	lc_df$ind_CI_ub[rowind] <- temp[, 3]
}


summary_figure_df <-
  lc_df[confint_rows, c("model", "target", "pt_est", "fam_CI_lb", "fam_CI_ub", "ind_CI_lb", "ind_CI_ub")]

summary_figure_df$model[summary_figure_df$model == "kde"] <- "KDE"
summary_figure_df$model[summary_figure_df$model == "kcde"] <- "KCDE"
summary_figure_df$model[summary_figure_df$model == "sarima"] <- "SARIMA"
summary_figure_df$model[summary_figure_df$model == "equal_weights"] <- "EW"
summary_figure_df$model[summary_figure_df$model == "em_stacking"] <- "CW"
summary_figure_df$model[summary_figure_df$model == "xgb_stacking_unregularized"] <- "FW-wu"
summary_figure_df$model[summary_figure_df$model == "xgb_stacking_reg_w"] <- "FW-reg-w"
summary_figure_df$model[summary_figure_df$model == "xgb_stacking_reg_wu"] <- "FW-reg-wu"
summary_figure_df$model[summary_figure_df$model == "xgb_stacking_reg_wui"] <- "FW-reg-wui"
summary_figure_df$model <- factor(summary_figure_df$model,
  levels = c("KDE", "KCDE", "SARIMA",
    "EW", "CW", "FW-wu",
    "FW-reg-w", "FW-reg-wu", "FW-reg-wui"))

summary_figure_df$target[summary_figure_df$target == "onset"] <- "Onset Timing"
summary_figure_df$target[summary_figure_df$target == "peak_inc"] <- "Peak Incidence"
summary_figure_df$target[summary_figure_df$target == "peak_week"] <- "Peak Timing"
summary_figure_df$target <- factor(summary_figure_df$target,
  levels = c("Onset Timing", "Peak Timing", "Peak Incidence"))

ggplot(summary_figure_df[model_row_inds, ]) +
  geom_point(aes(x = model, y = pt_est)) +
  geom_errorbar(aes(x = model, ymin = fam_CI_lb, ymax = fam_CI_ub)) +
  geom_errorbar(aes(x = model, ymin = ind_CI_lb, ymax = ind_CI_ub), width = 0.2) +
  facet_wrap(~ target, ncol = 1) +
  xlab("Model") +
  ylab("Mean Log Score") +
# 	scale_y_continuous(limits = c(0.6, 1), expand = c(0, 0)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
```

```{r test_phase_log_scores_contrasts_onset, echo=FALSE, eval=FALSE, fig.height=4, fig.cap="\\label{fig:performance-contrasts-onset-timing}Point estimates and confidence intervals for the difference in mean log score between the best model and each other model for predictions of season onset timing made before the season onset occurred.  Estimates are obtained from a mixed effects model with a separate fixed effect mean for the interaction of model and prediction target; random effects for each combination of region, season, model, and prediction target; and lag 1 autocorrelation nested within each combination of region, season, model, and prediction target.  The wider confidence interval bounds are simultaneous confidence intervals with an approximate familywise 95% coverage rate for all individual model means and all pairwise model contrasts for all prediction targets.  The inner confidence intervals are calculated separately, with approximate coverage rates of 95%.  Log scores of -Infinity were truncated at -10 before fitting this model."}
prediction_target <- "onset"

model_names_map <- c(
  kde = "KDE",
  kcde = "KCDE",
  sarima = "SARIMA",
  equal_weights = "EW",
  em_stacking = "CW",
  xgb_stacking_unregularized = "FW-wu",
  xgb_stacking_reg_w = "FW-reg-w",
  xgb_stacking_reg_wu = "FW-reg-wu",
  xgb_stacking_reg_wui = "FW-reg-wui"
)

inds <- model_row_inds[lc_df[model_row_inds, "target"] == prediction_target]
best_model_ind <- inds[which.max(lc_df$pt_est[inds])]
best_model <- lc_df$model[best_model_ind]
best_model_pretty <- model_names_map[best_model] %>%
  unname()
contrast_patterns_best_first <- paste0(best_model, "-", all_models, "-", prediction_target)
contrast_patterns_best_second <- paste0(all_models, "-", best_model, "-", prediction_target)

contrast_patterns <- c(
  contrast_patterns_best_first,
  contrast_patterns_best_second
)
contrast_inds <- which(lc_df$name %in% contrast_patterns)
matching_ind_in_contrast_patterns <- sapply(contrast_inds,
  function(contrast_ind) {
    which(contrast_patterns == lc_df$name[contrast_ind])
  })
contrast_model_candidates <- rep(model_names_map[all_models] %>% unname(), 2)
contrasting_model <- contrast_model_candidates[matching_ind_in_contrast_patterns]

summary_figure_df <-
  lc_df[contrast_inds, c("name", "pt_est", "fam_CI_lb", "fam_CI_ub", "ind_CI_lb", "ind_CI_ub")]
inds_second <- which(summary_figure_df$name %in% contrast_patterns_best_second)
summary_figure_df[inds_second, c("pt_est", "fam_CI_lb", "fam_CI_ub", "ind_CI_lb", "ind_CI_ub")] <-
  -1 * summary_figure_df[inds_second, c("pt_est", "fam_CI_lb", "fam_CI_ub", "ind_CI_lb", "ind_CI_ub")]
summary_figure_df$contrasting_model <- factor(contrasting_model,
  levels = c("KDE", "KCDE", "SARIMA",
    "EW", "CW", "FW-wu",
    "FW-reg-w", "FW-reg-wu", "FW-reg-wui"))


ggplot(summary_figure_df) +
  geom_point(aes(x = contrasting_model, y = pt_est)) +
  geom_errorbar(aes(x = contrasting_model, ymin = fam_CI_lb, ymax = fam_CI_ub)) +
  geom_errorbar(aes(x = contrasting_model, ymin = ind_CI_lb, ymax = ind_CI_ub), width = 0.2) +
#  facet_wrap(~ target, ncol = 1) +
  xlab("Contrasting Model") +
  ylab(paste0("Estimated Difference in Mean Log Scores:\n", best_model_pretty, " - Contrasting Model")) +
  ggtitle("Estimated Difference in Mean Performance for\nBest Model Relative to Each Other Model\nfor Predicting Onset Timing") +
# 	scale_y_continuous(limits = c(0.6, 1), expand = c(0, 0)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
```

```{r test_phase_log_scores_contrasts_peak_timing, echo=FALSE, eval=FALSE, fig.height=4, fig.cap="\\label{fig:performance-contrasts-peak-timing}Point estimates and confidence intervals for the difference in mean log score between the best model and each other model for predictions of peak timing made before the season onset occurred.  Estimates are obtained from a mixed effects model with a separate fixed effect mean for the interaction of model and prediction target; random effects for each combination of region, season, model, and prediction target; and lag 1 autocorrelation nested within each combination of region, season, model, and prediction target.  The wider confidence interval bounds are simultaneous confidence intervals with an approximate familywise 95% coverage rate for all individual model means and all pairwise model contrasts for all prediction targets.  The inner confidence intervals are calculated separately, with approximate coverage rates of 95%.  Log scores of -Infinity were truncated at -10 before fitting this model."}
prediction_target <- "peak_week"

model_names_map <- c(
  kde = "KDE",
  kcde = "KCDE",
  sarima = "SARIMA",
  equal_weights = "EW",
  em_stacking = "CW",
  xgb_stacking_unregularized = "FW-wu",
  xgb_stacking_reg_w = "FW-reg-w",
  xgb_stacking_reg_wu = "FW-reg-wu",
  xgb_stacking_reg_wui = "FW-reg-wui"
)

inds <- model_row_inds[lc_df[model_row_inds, "target"] == prediction_target]
best_model_ind <- inds[which.max(lc_df$pt_est[inds])]
best_model <- lc_df$model[best_model_ind]
best_model_pretty <- model_names_map[best_model] %>%
  unname()
contrast_patterns_best_first <- paste0(best_model, "-", all_models, "-", prediction_target)
contrast_patterns_best_second <- paste0(all_models, "-", best_model, "-", prediction_target)

contrast_patterns <- c(
  contrast_patterns_best_first,
  contrast_patterns_best_second
)
contrast_inds <- which(lc_df$name %in% contrast_patterns)
matching_ind_in_contrast_patterns <- sapply(contrast_inds,
  function(contrast_ind) {
    which(contrast_patterns == lc_df$name[contrast_ind])
  })
contrast_model_candidates <- rep(model_names_map[all_models] %>% unname(), 2)
contrasting_model <- contrast_model_candidates[matching_ind_in_contrast_patterns]

summary_figure_df <-
  lc_df[contrast_inds, c("name", "pt_est", "fam_CI_lb", "fam_CI_ub", "ind_CI_lb", "ind_CI_ub")]
inds_second <- which(summary_figure_df$name %in% contrast_patterns_best_second)
summary_figure_df[inds_second, c("pt_est", "fam_CI_lb", "fam_CI_ub", "ind_CI_lb", "ind_CI_ub")] <-
  -1 * summary_figure_df[inds_second, c("pt_est", "fam_CI_lb", "fam_CI_ub", "ind_CI_lb", "ind_CI_ub")]
summary_figure_df$contrasting_model <- factor(contrasting_model,
  levels = c("KDE", "KCDE", "SARIMA",
    "EW", "CW", "FW-wu",
    "FW-reg-w", "FW-reg-wu", "FW-reg-wui"))


ggplot(summary_figure_df) +
  geom_point(aes(x = contrasting_model, y = pt_est)) +
  geom_errorbar(aes(x = contrasting_model, ymin = fam_CI_lb, ymax = fam_CI_ub)) +
  geom_errorbar(aes(x = contrasting_model, ymin = ind_CI_lb, ymax = ind_CI_ub), width = 0.2) +
#  facet_wrap(~ target, ncol = 1) +
  xlab("Contrasting Model") +
  ylab(paste0("Estimated Difference in Mean Log Scores:\n", best_model_pretty, " - Contrasting Model")) +
  ggtitle("Estimated Difference in Mean Performance for\nBest Model Relative to Each Other Model\nfor Predicting Peak Timing") +
# 	scale_y_continuous(limits = c(0.6, 1), expand = c(0, 0)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
```

```{r test_phase_log_scores_contrasts_peak_inc, echo=FALSE, eval = FALSE, fig.height=4, fig.cap="\\label{fig:performance-contrasts-peak-inc}Point estimates and confidence intervals for the difference in mean log score between the best model and each other model for predictions of peak incidence made before the season peak occurred.  The wider confidence interval bounds are simultaneous confidence intervals with an approximate familywise 95% coverage rate for all individual model means and all pairwise model contrasts for all prediction targets.  The inner confidence intervals are calculated separately, with approximate coverage rates of 95%.  Log scores of -Infinity were truncated at -10 before fitting this model."}
prediction_target <- "peak_inc"

model_names_map <- c(
  kde = "KDE",
  kcde = "KCDE",
  sarima = "SARIMA",
  equal_weights = "EW",
  em_stacking = "CW",
  xgb_stacking_unregularized = "FW-wu",
  xgb_stacking_reg_w = "FW-reg-w",
  xgb_stacking_reg_wu = "FW-reg-wu",
  xgb_stacking_reg_wui = "FW-reg-wui"
)

inds <- model_row_inds[lc_df[model_row_inds, "target"] == prediction_target]
best_model_ind <- inds[which.max(lc_df$pt_est[inds])]
best_model <- lc_df$model[best_model_ind]
best_model_pretty <- model_names_map[best_model] %>%
  unname()
contrast_patterns_best_first <- paste0(best_model, "-", all_models, "-", prediction_target)
contrast_patterns_best_second <- paste0(all_models, "-", best_model, "-", prediction_target)

contrast_patterns <- c(
  contrast_patterns_best_first,
  contrast_patterns_best_second
)
contrast_inds <- which(lc_df$name %in% contrast_patterns)
matching_ind_in_contrast_patterns <- sapply(contrast_inds,
  function(contrast_ind) {
    which(contrast_patterns == lc_df$name[contrast_ind])
  })
contrast_model_candidates <- rep(model_names_map[all_models] %>% unname(), 2)
contrasting_model <- contrast_model_candidates[matching_ind_in_contrast_patterns]

summary_figure_df <-
  lc_df[contrast_inds, c("name", "pt_est", "fam_CI_lb", "fam_CI_ub", "ind_CI_lb", "ind_CI_ub")]
inds_second <- which(summary_figure_df$name %in% contrast_patterns_best_second)
summary_figure_df[inds_second, c("pt_est", "fam_CI_lb", "fam_CI_ub", "ind_CI_lb", "ind_CI_ub")] <-
  -1 * summary_figure_df[inds_second, c("pt_est", "fam_CI_lb", "fam_CI_ub", "ind_CI_lb", "ind_CI_ub")]
summary_figure_df$contrasting_model <- factor(contrasting_model,
  levels = c("KDE", "KCDE", "SARIMA",
    "EW", "CW", "FW-wu",
    "FW-reg-w", "FW-reg-wu", "FW-reg-wui"))


ggplot(summary_figure_df) +
  geom_point(aes(x = contrasting_model, y = pt_est)) +
  geom_errorbar(aes(x = contrasting_model, ymin = fam_CI_lb, ymax = fam_CI_ub)) +
  geom_errorbar(aes(x = contrasting_model, ymin = ind_CI_lb, ymax = ind_CI_ub), width = 0.2) +
#  facet_wrap(~ target, ncol = 1) +
  xlab("Contrasting Model") +
  ylab(paste0("Estimated Difference in Mean Log Scores:\n", best_model_pretty, " - Contrasting Model")) +
  ggtitle("Estimated Difference in Mean Performance for\nBest Model Relative to Each Other Model\nfor Predicting Peak Incidence") +
# 	scale_y_continuous(limits = c(0.6, 1), expand = c(0, 0)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
```



```{r test_phase_predictive_dists_national_onset2, echo=FALSE, cache=TRUE, fig.height=9, fig.cap="Predictive distributions for onset timing at the national level from just the FW-reg-w method, facetted by season."}
region_season_obs_quantities <- flu_data %>%
  select_(.dots = c("region", "season")) %>%
  distinct() %>%
  filter(season %in% paste0(2011:2015, "/", 2012:2016)) %>%
  mutate(
    observed_onset_week = NA,
    observed_peak_week = NA,
    observed_peak_inc = NA
  )

for(rs_row in seq_len(nrow(region_season_obs_quantities))) {
  temp <- get_observed_seasonal_quantities(
    data = flu_data[flu_data$region == region_season_obs_quantities$region[rs_row], , drop = FALSE],
    season = region_season_obs_quantities$season[rs_row],
    first_CDC_season_week = 10,
    last_CDC_season_week = 42,
    onset_baseline =
      get_onset_baseline(region = region_season_obs_quantities$region[rs_row],
        season = region_season_obs_quantities$season[rs_row]),
    incidence_var = "weighted_ili",
    incidence_bins = data.frame(
      lower = c(0, seq(from = 0.05, to = 12.95, by = 0.1)),
      upper = c(seq(from = 0.05, to = 12.95, by = 0.1), Inf)),
    incidence_bin_names = as.character(seq(from = 0, to = 13, by = 0.1))
  )

  region_season_obs_quantities$observed_onset_week[rs_row] <-
    temp$observed_onset_week
  region_season_obs_quantities$observed_peak_week[rs_row] <-
    temp$observed_peak_week[1]
  region_season_obs_quantities$observed_peak_inc[rs_row] <-
    temp$observed_peak_inc
}

region_season_obs_quantities <- region_season_obs_quantities %>%
  transmute(
    region = gsub(" ", "", region),
    analysis_time_season = season,
    observed_onset_week = factor(observed_onset_week,
      levels = c(as.character(10:42), "none")),
    observed_peak_week = observed_peak_week,
    observed_peak_inc = observed_peak_inc
  )
region_season_obs_quantities$region[region_season_obs_quantities$region == "X"] <- "National"

all_models <- c("kde", "kcde", "sarima", "equal_weights", "em_stacking", "xgb_stacking_unregularized", "xgb_stacking_reg_w", "xgb_stacking_reg_wu", "xgb_stacking_reg_wui")
all_models <- "xgb_stacking_reg_w"
all_targets <- c("onset", "peak_week", "peak_inc")
all_targets <- "onset"
preds <- assemble_predictions(
    preds_path = file.path(awes_path, "evaluation/test-predictions"),
    models = all_models,
    prediction_targets = all_targets,
    prediction_types = "bin_log_probs"
  ) %>%
  filter(analysis_time_season_week %in% 10:40) %>%
  gather_("bin", "log_prob", paste0("onset_bin_", c(10:42, "none"), "_log_prob")) %>%
  mutate(
    bin = factor(substr(bin, 11, nchar(bin) - 9)),
    model = factor(model, levels = all_models),
    prob = exp(log_prob)
  )


p_onset <- ggplot(data = preds %>% filter(region == "National")) +
  geom_line(aes(x = as.numeric(bin), y = prob, colour = analysis_time_season_week, group = analysis_time_season_week)) +
  geom_vline(aes(xintercept = as.numeric(observed_onset_week)),
    color = "red",
    data = region_season_obs_quantities %>% filter(region == "National")) +
  scale_color_continuous("Analysis Time\nSeason Week",
    low = "#56B1F7", high = "#132B43") +
  scale_x_continuous(breaks = c(seq(from = 1, to = 34, by = 2), 34),
    labels = levels(preds$bin)[c(seq(from = 1, to = 34, by = 2), 34)],
    expand = c(0, 0.5)) +
  facet_wrap( ~ analysis_time_season, ncol = 1) +
  ylab("Predictive Probability") +
  xlab("Onset Week") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

print(p_onset)
```




```{r test_phase_predictive_dists_national_peak_timing, echo=FALSE, cache=TRUE, fig.height=9, fig.cap="Predictive distributions for peak timing at the national level from just the FW-reg-w method, facetted by season."}
all_models <- "xgb_stacking_reg_w"
all_targets <- c("onset", "peak_week", "peak_inc")
all_targets <- "peak_week"
preds <- assemble_predictions(
    preds_path = file.path(awes_path, "evaluation/test-predictions"),
    models = all_models,
    prediction_targets = all_targets,
    prediction_types = "bin_log_probs"
  ) %>%
  filter(analysis_time_season_week %in% 10:40) %>%
  gather_("bin", "log_prob", paste0("peak_week_bin_", c(10:42), "_log_prob")) %>%
  mutate(
    bin = substr(bin, 15, nchar(bin) - 9),
    model = factor(model, levels = all_models),
    prob = exp(log_prob)
  )


p <- ggplot(data = preds %>% filter(region == "National")) +
  geom_line(aes(x = as.numeric(bin), y = prob, colour = analysis_time_season_week, group = analysis_time_season_week)) +
  geom_vline(aes(xintercept = as.numeric(observed_peak_week)),
    color = "red",
    data = region_season_obs_quantities %>% filter(region == "National")) +
  scale_color_continuous("Analysis Time\nSeason Week",
    low = "#56B1F7", high = "#132B43") +
  scale_x_continuous(breaks = seq(from = 10, to = 42, by = 2),
    labels = seq(from = 10, to = 42, by = 2),
    expand = c(0, 0)) +
  facet_wrap( ~ analysis_time_season, ncol = 1) +
  ylab("Predictive Probability") +
  xlab("Peak Week") +
  theme_bw()

print(p)
```


```{r test_phase_predictive_dists_national_peak_incidence, echo=FALSE, cache=TRUE, fig.height=9, fig.cap="Predictive distributions for peak incidence at the national level from just the FW-reg-w method, facetted by season."}
all_models <- "xgb_stacking_reg_w"
all_targets <- c("onset", "peak_week", "peak_inc")
all_targets <- "peak_inc"
preds <- assemble_predictions(
    preds_path = file.path(awes_path, "evaluation/test-predictions"),
    models = all_models,
    prediction_targets = all_targets,
    prediction_types = "bin_log_probs"
  ) %>%
  filter(analysis_time_season_week %in% 10:40) %>%
  gather_("bin", "log_prob", paste0("peak_inc_bin_", seq(from = 0, to = 13, by = 0.1), "_log_prob")) %>%
  mutate(
    bin = as.numeric(substr(bin, 14, nchar(bin) - 9)),
    model = factor(model, levels = all_models),
    prob = exp(log_prob)
  )


p <- ggplot(data = preds %>% filter(region == "National")) +
  geom_line(aes(x = bin, y = prob, colour = analysis_time_season_week, group = analysis_time_season_week)) +
  geom_vline(aes(xintercept = as.numeric(observed_peak_inc)),
    color = "red",
    data = region_season_obs_quantities %>% filter(region == "National")) +
  scale_color_continuous("Analysis Time\nSeason Week",
    low = "#56B1F7", high = "#132B43") +
  facet_wrap( ~ analysis_time_season, ncol = 1) +
  ylab("Predictive Probability") +
  xlab("Peak Incidence") +
  theme_bw()

print(p)
```

```{r test_phase_log_scores_by_region_season_difference_density, echo=FALSE, cache=TRUE, fig.height=7.5, fig.cap="Density plots representing the distribution of log score differences from predictions made by the FW-reg-w and SARIMA models for predictions of onset timing across all regions and test phase seasons.  The horizontal axis represents the difference in log scores achieved by the FW-reg-w and SARIMA models for predictions made in a particular week; positive values indicate that FW-reg-w outperformed SARIMA for that prediction.  The vertical line indicates the mean log score difference for all predictions made before the onset occurred in the given region and season."}
awes_path <- find.package("awes")



region_season_obs_quantities <- flu_data %>%
  select_(.dots = c("region", "season")) %>%
  distinct() %>%
  filter(season %in% paste0(2011:2015, "/", 2012:2016)) %>%
  mutate(
    observed_onset_week = NA,
    observed_peak_week = NA
  )

for(rs_row in seq_len(nrow(region_season_obs_quantities))) {
  temp <- get_observed_seasonal_quantities(
    data = flu_data[flu_data$region == region_season_obs_quantities$region[rs_row], , drop = FALSE],
    season = region_season_obs_quantities$season[rs_row],
    first_CDC_season_week = 10,
    last_CDC_season_week = 42,
    onset_baseline =
      get_onset_baseline(region = region_season_obs_quantities$region[rs_row],
        season = region_season_obs_quantities$season[rs_row]),
    incidence_var = "weighted_ili",
    incidence_bins = data.frame(
      lower = c(0, seq(from = 0.05, to = 12.95, by = 0.1)),
      upper = c(seq(from = 0.05, to = 12.95, by = 0.1), Inf)),
    incidence_bin_names = as.character(seq(from = 0, to = 13, by = 0.1))
  )

  region_season_obs_quantities$observed_onset_week[rs_row] <-
    temp$observed_onset_week
  region_season_obs_quantities$observed_peak_week[rs_row] <-
    temp$observed_peak_week[1]
}

region_season_obs_quantities$observed_onset_week[
  region_season_obs_quantities$observed_onset_week == "none"] <- 42
region_season_obs_quantities <- region_season_obs_quantities %>%
  transmute(
    region = ifelse(region == "X", "National", gsub(" ", "", region)),
    analysis_time_season = season,
    observed_onset_week = as.numeric(observed_onset_week),
    observed_peak_week = observed_peak_week
  )

all_models <- c("kde", "kcde", "sarima", "equal_weights", "em_stacking", "xgb_stacking_unregularized", "xgb_stacking_reg_w", "xgb_stacking_reg_wu", "xgb_stacking_reg_wui")
all_targets <- c("onset", "peak_week", "peak_inc")
preds <- assemble_predictions(
  preds_path = file.path(awes_path, "evaluation/test-predictions"),
  models = all_models,
  prediction_targets = all_targets,
  prediction_types = "log_score"
) %>%
  filter(analysis_time_season_week %in% 10:40) %>%
  gather_("prediction_target", "log_score",
    c("onset_log_score", "peak_week_log_score", "peak_inc_log_score")) %>%
  mutate(
    prediction_target = substr(prediction_target, 1, nchar(prediction_target) - 10),
    score = exp(log_score)
  )

preds$log_score[is.infinite(preds$log_score)] <- -10
preds <- preds %>%
  left_join(region_season_obs_quantities, by = c("region", "analysis_time_season")) %>%
  mutate(
    before_onset = (analysis_time_season_week < observed_onset_week),
    before_peak = (analysis_time_season_week < observed_peak_week))

preds$before_target_date <- ifelse(
  preds$prediction_target == "onset",
  c("on or after\ntarget date", "before\ntarget date")[preds$before_onset + 1],
  c("on or after\ntarget date", "before\ntarget date")[preds$before_peak + 1]
)

preds$model[preds$model == "kde"] <- "KDE"
preds$model[preds$model == "kcde"] <- "KCDE"
preds$model[preds$model == "sarima"] <- "SARIMA"
preds$model[preds$model == "equal_weights"] <- "EW"
preds$model[preds$model == "em_stacking"] <- "CW"
preds$model[preds$model == "xgb_stacking_unregularized"] <- "FW-wu"
preds$model[preds$model == "xgb_stacking_reg_w"] <- "FW-reg-w"
preds$model[preds$model == "xgb_stacking_reg_wu"] <- "FW-reg-wu"
preds$model[preds$model == "xgb_stacking_reg_wui"] <- "FW-reg-wui"
preds$model <- factor(preds$model,
  levels = c("KDE", "KCDE", "SARIMA",
    "EW", "CW", "FW-wu",
    "FW-reg-w", "FW-reg-wu", "FW-reg-wui"))

preds$prediction_target[preds$prediction_target == "onset"] <- "Onset Timing"
preds$prediction_target[preds$prediction_target == "peak_inc"] <- "Peak Incidence"
preds$prediction_target[preds$prediction_target == "peak_week"] <- "Peak Timing"
preds$prediction_target <- factor(preds$prediction_target,
  levels = c("Onset Timing", "Peak Timing", "Peak Incidence"))

preds <- preds %>%
  mutate(
    region = factor(region),
    analysis_time_season = factor(analysis_time_season)
  )

preds_wide <- preds %>%
  dplyr::filter(before_target_date == "before\ntarget date") %>%
  dplyr::select(-score) %>%
  tidyr::spread(model, log_score)

all_models <- unique(preds$model)
for(model_val in all_models) {
  preds_wide[[paste0("diff_xgb_stacking_reg_w_vs_", model_val)]] <-
  preds_wide[["FW-reg-w"]] - preds_wide[[model_val]]
#    preds_wide[["xgb_stacking_reg_w"]] - preds_wide[[model_val]]
}

#ggplot(data = preds_wide %>% filter(prediction_target == "onset")) +
#  geom_density(aes(x = diff_xgb_stacking_reg_w_vs_sarima)) +
ggplot(data = preds_wide %>% filter(prediction_target == "Onset Timing")) +
  geom_density(aes(x = diff_xgb_stacking_reg_w_vs_SARIMA)) +
  geom_vline(xintercept = 0) +
  geom_vline(aes(xintercept = mean_log_score_diff),
    color = "red",
    linetype = 2,
    data = preds_wide %>% filter(prediction_target == "Onset Timing") %>%
#    data = preds_wide %>% filter(prediction_target == "onset") %>%
      group_by_(.dots = c("analysis_time_season", "region")) %>%
      summarize(mean_log_score_diff = mean(diff_xgb_stacking_reg_w_vs_SARIMA))) +
#      summarize(mean_log_score_diff = mean(diff_xgb_stacking_reg_w_vs_sarima))) +
#  facet_grid(region ~ analysis_time_season, scales = "free_y") +
  facet_grid(region ~ analysis_time_season, scales = "fixed") +
#  scale_y_sqrt() +
  ylab("Density of Log Score Differences") +
  xlab("Difference in Log Scores: FW-reg-w - SARIMA") +
  theme_bw()
```

```{r test_phase_log_scores_by_target_difference_density, echo=FALSE, cache=TRUE, fig.height=7.5, fig.cap="Density plots representing the distribution of log score differences from predictions made by the FW-reg-w and SARIMA models for predictions of each prediction target, aggregated across all regions and test phase seasons.  The horizontal axis represents the difference in log scores achieved by the FW-reg-w and SARIMA models for predictions made in a particular week; positive values indicate that FW-reg-w outperformed SARIMA for that prediction.  The vertical line indicates the mean log score difference for all predictions made before the onset or season peak occurred."}
#temp <- preds_wide %>%
#  group_by(.dots = c("analysis_time_season", "region", "prediction_target")) %>%
#  summarize(mean_log_score_diff = mean(diff_xgb_stacking_reg_w_vs_sarima))
#
#ggplot(data = temp) +
#  geom_density(aes(x = mean_log_score_diff)) +
#  theme_bw()


ggplot(data = preds_wide) +
  geom_density(aes(x = diff_xgb_stacking_reg_w_vs_SARIMA)) +
  geom_vline(xintercept = 0) +
  geom_vline(aes(xintercept = mean_log_score_diff),
    color = "red",
    linetype = 2,
    data = preds_wide %>%
      group_by_(.dots = c("prediction_target")) %>%
      summarize(mean_log_score_diff = mean(diff_xgb_stacking_reg_w_vs_SARIMA))) +
#      summarize(mean_log_score_diff = mean(diff_xgb_stacking_reg_w_vs_sarima))) +
#  facet_grid(region ~ analysis_time_season, scales = "free_y") +
  facet_wrap( ~ prediction_target, scales = "fixed", ncol = 1) +
#  scale_y_sqrt() +
  ylab("Density of Log Score Differences") +
  xlab("Difference in Log Scores: FW-reg-w - SARIMA") +
  theme_bw()
```




```{r perm_test_means, echo=FALSE, cache = TRUE}
all_models <- c("KDE", "KCDE", "SARIMA", "EW", "CW", "FW-wu", "FW-reg-w", "FW-reg-wu", "FW-reg-wui")

preds_median_ls_by_model_target <- preds %>%
  group_by_("model", "prediction_target") %>%
  summarize(ls_median = median(log_score))

preds <- preds %>%
  left_join(preds_median_ls_by_model_target) %>%
  mutate(abs_log_score_diff_from_median = abs(log_score - ls_median))

preds_wide <- preds %>%
  dplyr::filter(before_target_date == "before\ntarget date") %>%
  dplyr::select(-score, -ls_median, -abs_log_score_diff_from_median) %>%
  tidyr::spread(model, log_score)

realized_means <- preds %>%
  filter(before_target_date == "before\ntarget date") %>%
  group_by(model) %>%
  summarize(mean_val = mean(log_score))

registerDoMC(cores = 3)
m_combos <- expand.grid(
  m1_ind = seq_along(all_models),
  m2_ind = seq_along(all_models)) %>%
  filter(m1_ind < m2_ind)
m_combos$m1 <- all_models[m_combos$m1_ind]
m_combos$m2 <- all_models[m_combos$m2_ind]

get_one_perm <- function(preds_wide_perm, all_models, group_by_vars = NULL) {
  model_cols <- which(colnames(preds_wide_perm) %in% all_models)

  model_scores <- preds_wide_perm[, model_cols]
  model_cols <- seq_along(model_cols)

  if(is.null(group_by_vars)) {
    for(i in seq_len(nrow(preds_wide_perm))) {
      model_scores[i, model_cols] <- base::sample(model_scores[i, model_cols])
    }
  } else {
    groups <- preds_wide_perm[, group_by_vars] %>%
      distinct()
    for(group_ind in seq_len(nrow(groups))) {
      preds_inds <- which(
        preds_wide_perm[[group_by_vars[1]]] == groups[group_ind, group_by_vars[1]] &
        preds_wide_perm[[group_by_vars[2]]] == groups[group_ind, group_by_vars[2]] &
        preds_wide_perm[[group_by_vars[3]]] == groups[group_ind, group_by_vars[3]]
      )
      # preds_inds <- sapply(
      #   group_by_vars,
      #   function(group_by_var) {
      #     preds_wide_perm[[group_by_var]] == groups[group_ind, group_by_var]
      #   }) %>%
      #   apply(1, all)
      model_scores[preds_inds, model_cols] <- model_scores[preds_inds, base::sample(model_cols)]
    }
  }

  return(model_scores)
}

#perms_list <- foreach(i = seq_len(nrow(m_combos))) %dopar% {
#  set.seed(13704) # from random.org
#  seed_vals <- runif(nrow(m_combos), 1, 10^5)
#  set.seed(seed_vals[i])
#
#  model_pair <- m_combos[i, c("m1", "m2")]
#
#  perm_model_scores <-
#    lapply(
#      1:2000,
##      1:100,
#      function(i) {
#        get_one_perm(
#          preds_wide_perm = preds_wide %>% filter(before_target_date == "before\ntarget date"),
#          all_models = model_pair,
#          group_by_vars = c("region", "analysis_time_season", "prediction_target"))
#      }
#    )
#
#  return(list(m1 = model_pair[1],
#    m2 = model_pair[2],
#    perm_model_scores = perm_model_scores))
#}


#perms_list <- foreach(i = seq_len(nrow(m_combos))) %dopar% {
#perms_list <- foreach(i = seq_len(3)) %dopar% {
perm_test_res <- foreach(i = seq_len(nrow(m_combos))) %dopar% {
  set.seed(60929) # from random.org
  seed_vals <- runif(nrow(m_combos), 1, 10^5)
  set.seed(seed_vals[i])

  model_pair <- m_combos[i, c("m1", "m2")]

  perm_model_scores <-
    lapply(
      1:10000,
#      1:101,
      function(i) {
        get_one_perm(
          preds_wide_perm = preds_wide %>% filter(before_target_date == "before\ntarget date"),
          all_models = model_pair,
          group_by_vars = c("region", "analysis_time_season", "prediction_target"))
      }
    )

  return(data.frame(m1 = model_pair[1],
    m2 = model_pair[2],
    pval_diff = sapply(
      perm_model_scores,
      function(ms) {
        mean_ms <- apply(ms, 2, mean)
        abs(mean_ms[2] - mean_ms[1]) >=
          abs(realized_means$mean_val[realized_means$model == unlist(model_pair[2])] -
            realized_means$mean_val[realized_means$model == unlist(model_pair[1])])
      }) %>%
      mean()
    ))
#    perm_model_scores = perm_model_scores))
}
```

```{r perm_test_means_plot, echo=FALSE, eval = FALSE}
#perm_test_res <- lapply(perms_list,
#  function(comp) {
#    data.frame(
#      m1 = unlist(comp$m1),
#      m2 = unlist(comp$m2),
#      pval_diff = sapply(
#        comp$perm_model_scores,
#        function(ms) {
#          mean_ms <- apply(ms, 2, mean)
#          abs(mean_ms[2] - mean_ms[1]) >=
#            abs(realized_means$mean_val[realized_means$model == unlist(comp$m2)] -
#              realized_means$mean_val[realized_means$model == unlist(comp$m1)])
#        }) %>%
#        mean()
#    )
#  })

ptr_as_df <- rbind.fill(perm_test_res)
ptr_as_df2 <- ptr_as_df
ptr_as_df2$m1 <- ptr_as_df$m2
ptr_as_df2$m2 = ptr_as_df$m1
ptr_as_df_c <- rbind(ptr_as_df, ptr_as_df2) %>%
  dplyr::mutate(m1 = factor(as.character(m1), levels = all_models),
    m2 = factor(as.character(m2), levels = all_models)) %>%
  dplyr::left_join(realized_means, by = c("m1" = "model")) %>%
  dplyr::mutate(mean_m1 = mean_val) %>%
  dplyr::select(-mean_val) %>%
  dplyr::left_join(realized_means, by = c("m2" = "model")) %>%
  dplyr::mutate(mean_m2 = mean_val) %>%
  dplyr::select(-mean_val) %>%
  dplyr::mutate(diff_means = mean_m2 - mean_m1)

ggplot(data = ptr_as_df_c) +
  geom_tile(aes(x = m1, y = m2, fill = diff_means)) +
  geom_text(aes(x = m1, y = m2, label=paste0(
    format(round(diff_means, 3), nsmall = 3),
    "\n(",
    format(round(pval_diff, 3), nsmall = 3),
    ")")),
    size = 3) +
#  geom_text(aes(x = m1, y = m2, label=paste0(pval_diff)),
#    size = 3) +
  scale_fill_gradient2("Difference\nin Mean Scores",
#    breaks = 1:9,
#    labels = as.character(1:9),
    low = "#2166ac",
    mid = "#f7f7f7",
    high = "#b2182b",
    midpoint = 0) +
  theme_bw()
```


```{r mad_perm_test, echo = FALSE, cache = TRUE}
preds_wide <- preds %>%
  dplyr::filter(before_target_date == "before\ntarget date") %>%
  dplyr::select(-score, -ls_median, -log_score) %>%
  tidyr::spread(model, abs_log_score_diff_from_median)

realized_means <- preds %>%
  filter(before_target_date == "before\ntarget date") %>%
  group_by(model) %>%
  summarize(mean_val = mean(abs_log_score_diff_from_median))

m_combos <- expand.grid(
  m1_ind = seq_along(all_models),
  m2_ind = seq_along(all_models)) %>%
  filter(m1_ind < m2_ind)
m_combos$m1 <- all_models[m_combos$m1_ind]
m_combos$m2 <- all_models[m_combos$m2_ind]

#perms_list <- foreach(i = seq_len(nrow(m_combos))) %dopar% {
#perms_list <- foreach(i = seq_len(3)) %dopar% {
perm_test_res <- foreach(i = seq_len(nrow(m_combos))) %dopar% {
  set.seed(60929) # from random.org
  seed_vals <- runif(nrow(m_combos), 1, 10^5)
  set.seed(seed_vals[i])

  model_pair <- m_combos[i, c("m1", "m2")]

  perm_model_scores <-
    lapply(
      1:10000,
#      1:101,
      function(i) {
        get_one_perm(
          preds_wide_perm = preds_wide %>% filter(before_target_date == "before\ntarget date"),
          all_models = model_pair,
          group_by_vars = c("region", "analysis_time_season", "prediction_target"))
      }
    )

  return(data.frame(m1 = model_pair[1],
    m2 = model_pair[2],
    pval_diff = sapply(
      perm_model_scores,
      function(ms) {
        mean_ms <- apply(ms, 2, mean)
        abs(mean_ms[2] - mean_ms[1]) >=
          abs(realized_means$mean_val[realized_means$model == unlist(model_pair[2])] -
            realized_means$mean_val[realized_means$model == unlist(model_pair[1])])
      }) %>%
      mean()
    ))
#    perm_model_scores = perm_model_scores))
}

#perm_test_res <- lapply(perms_list,
#  function(comp) {
#    data.frame(
#      m1 = unlist(comp$m1),
#      m2 = unlist(comp$m2),
#      pval_diff = sapply(
#        comp$perm_model_scores,
#        function(ms) {
#          mean_ms <- apply(ms, 2, mean)
#          abs(mean_ms[2] - mean_ms[1]) >=
#            abs(realized_means$mean_val[realized_means$model == unlist(comp$m2)] -
#              realized_means$mean_val[realized_means$model == unlist(comp$m1)])
#        }) %>%
#        mean()
#    )
#  })
```

```{r mad_perm_test_plot, echo = FALSE, eval = FALSE}
ptr_as_df <- rbind.fill(perm_test_res)
ptr_as_df2 <- ptr_as_df
ptr_as_df2$m1 <- ptr_as_df$m2
ptr_as_df2$m2 = ptr_as_df$m1
ptr_as_df_c <- rbind(ptr_as_df, ptr_as_df2) %>%
  dplyr::mutate(m1 = factor(as.character(m1), levels = all_models),
    m2 = factor(as.character(m2), levels = all_models)) %>%
  dplyr::left_join(realized_means, by = c("m1" = "model")) %>%
  dplyr::mutate(mean_m1 = mean_val) %>%
  dplyr::select(-mean_val) %>%
  dplyr::left_join(realized_means, by = c("m2" = "model")) %>%
  dplyr::mutate(mean_m2 = mean_val) %>%
  dplyr::select(-mean_val) %>%
  dplyr::mutate(diff_means = mean_m2 - mean_m1)

ggplot(data = ptr_as_df_c) +
  geom_tile(aes(x = m1, y = m2, fill = diff_means)) +
  geom_text(aes(x = m1, y = m2, label=paste0(
    format(round(diff_means, 3), nsmall = 3),
    "\n(",
    format(round(pval_diff, 3), nsmall = 3),
    ")")),
    size = 3) +
#  geom_text(aes(x = m1, y = m2, label=paste0(pval_diff)),
#    size = 3) +
  scale_fill_gradient2("Difference\nin Mean Scores",
#    breaks = 1:9,
#    labels = as.character(1:9),
    low = "#2166ac",
    mid = "#f7f7f7",
    high = "#b2182b",
    midpoint = 0) +
  theme_bw()
```



```{r test_phase_log_scores_by_season_heatmap_rank_rounded, echo=FALSE, cache=TRUE, fig.height=8, fig.cap="\\label{fig:test_phase_log_scores_heatmap}Model performance ranked by mean log score within each of the five test seasons for predictions made before the target (season onset or peak) occurred.  Averages are taken across all regions."}
awes_path <- find.package("awes")

region_season_obs_quantities <- flu_data %>%
  select_(.dots = c("region", "season")) %>%
  distinct() %>%
  filter(season %in% paste0(2011:2015, "/", 2012:2016)) %>%
  mutate(
    observed_onset_week = NA,
    observed_peak_week = NA
  )

for(rs_row in seq_len(nrow(region_season_obs_quantities))) {
  temp <- get_observed_seasonal_quantities(
    data = flu_data[flu_data$region == region_season_obs_quantities$region[rs_row], , drop = FALSE],
    season = region_season_obs_quantities$season[rs_row],
    first_CDC_season_week = 10,
    last_CDC_season_week = 42,
    onset_baseline =
      get_onset_baseline(region = region_season_obs_quantities$region[rs_row],
        season = region_season_obs_quantities$season[rs_row]),
    incidence_var = "weighted_ili",
    incidence_bins = data.frame(
      lower = c(0, seq(from = 0.05, to = 12.95, by = 0.1)),
      upper = c(seq(from = 0.05, to = 12.95, by = 0.1), Inf)),
    incidence_bin_names = as.character(seq(from = 0, to = 13, by = 0.1))
  )

  region_season_obs_quantities$observed_onset_week[rs_row] <-
    temp$observed_onset_week
  region_season_obs_quantities$observed_peak_week[rs_row] <-
    temp$observed_peak_week[1]
}

region_season_obs_quantities$observed_onset_week[
  region_season_obs_quantities$observed_onset_week == "none"] <- 42
region_season_obs_quantities <- region_season_obs_quantities %>%
  transmute(
    region = gsub(" ", "", region),
    analysis_time_season = season,
    observed_onset_week = as.numeric(observed_onset_week),
    observed_peak_week = observed_peak_week
  )

all_models <- c("kde", "kcde", "sarima", "equal_weights", "em_stacking", "xgb_stacking_unregularized", "xgb_stacking_reg_w", "xgb_stacking_reg_wu", "xgb_stacking_reg_wui")
all_targets <- c("onset", "peak_week", "peak_inc")
preds <- assemble_predictions(
  preds_path = file.path(awes_path, "evaluation/test-predictions"),
  models = all_models,
  prediction_targets = all_targets,
  prediction_types = "log_score"
) %>%
  filter(analysis_time_season_week %in% 10:40) %>%
  gather_("prediction_target", "log_score",
    c("onset_log_score", "peak_week_log_score", "peak_inc_log_score")) %>%
  mutate(
    prediction_target = substr(prediction_target, 1, nchar(prediction_target) - 10),
    score = exp(log_score)
  )

preds$log_score[is.infinite(preds$log_score)] <- -10
preds <- preds %>%
  left_join(region_season_obs_quantities, by = c("region", "analysis_time_season")) %>%
  mutate(
    before_onset = (analysis_time_season_week < observed_onset_week),
    before_peak = (analysis_time_season_week < observed_peak_week))

preds$before_target_date <- ifelse(
  preds$prediction_target == "onset",
  c("on or after\ntarget date", "before\ntarget date")[preds$before_onset + 1],
  c("on or after\ntarget date", "before\ntarget date")[preds$before_peak + 1]
)

preds$model[preds$model == "kde"] <- "KDE"
preds$model[preds$model == "kcde"] <- "KCDE"
preds$model[preds$model == "sarima"] <- "SARIMA"
preds$model[preds$model == "equal_weights"] <- "EW"
preds$model[preds$model == "em_stacking"] <- "CW"
preds$model[preds$model == "xgb_stacking_unregularized"] <- "FW-wu"
preds$model[preds$model == "xgb_stacking_reg_w"] <- "FW-reg-w"
preds$model[preds$model == "xgb_stacking_reg_wu"] <- "FW-reg-wu"
preds$model[preds$model == "xgb_stacking_reg_wui"] <- "FW-reg-wui"
preds$model <- factor(preds$model,
  levels = c("KDE", "KCDE", "SARIMA",
    "EW", "CW", "FW-wu",
    "FW-reg-w", "FW-reg-wu", "FW-reg-wui"))

preds$prediction_target[preds$prediction_target == "onset"] <- "Onset Timing"
preds$prediction_target[preds$prediction_target == "peak_inc"] <- "Peak Incidence"
preds$prediction_target[preds$prediction_target == "peak_week"] <- "Peak Timing"
preds$prediction_target <- factor(preds$prediction_target,
  levels = c("Onset Timing", "Peak Timing", "Peak Incidence"))

preds <- preds %>%
  mutate(
    region = factor(region),
    analysis_time_season = factor(analysis_time_season)
  )

res <- mean(log_score ~ model + prediction_target + analysis_time_season,
  data = preds[preds$before_target_date == "before\ntarget date", ])
temp <- strsplit(names(res), ".", fixed = TRUE) %>%
  unlist() %>%
  matrix(ncol = 3, byrow = TRUE)
res <- cbind(temp, res) %>%
  as.data.frame(stringsAsFactors = FALSE) %>%
  `colnames<-`(c("model", "prediction_target", "season", "mean_log_score")) %>%
  `rownames<-`(NULL) %>%
  group_by_(.dots = c("prediction_target", "season")) %>%
  mutate(mean_log_score = as.numeric(mean_log_score),
    rank = rank(-1 * round(as.numeric(mean_log_score), 2)))
res$prediction_target <- factor(res$prediction_target,
  levels = c("Onset Timing", "Peak Timing", "Peak Incidence"))
res$model <- factor(res$model,
  levels = c("KDE", "KCDE", "SARIMA",
    "EW", "CW", "FW-wu",
    "FW-reg-w", "FW-reg-wu", "FW-reg-wui"))

overall_rank <- res %>% group_by(prediction_target, model) %>%
    summarize(
        season="Average Rank",
#        mean_log_score = mean(mean_log_score),
#        mean_log_score = "",
        mean_log_score = format(round(mean(as.numeric(rank)), 2), nsmall=2), # gets printed in table cell
        rank = round(mean(as.numeric(rank)), 2)
        ) %>% ungroup()

minimum_rank <- res %>% group_by(prediction_target, model) %>%
    summarize(
        season="Lowest Rank",
#        mean_log_score = mean(mean_log_score),
#        mean_log_score = "",
        mean_log_score = format(round(max(as.numeric(rank)), 2), nsmall=2), # gets printed in table cell
        rank = round(max(as.numeric(rank)), 2)
        ) %>% ungroup()

overall_log_score <- res %>% group_by(prediction_target, model) %>%
    summarize(
        season="Average Log Score",
        mean_log_score = format(round(mean(mean_log_score), 2), nsmall=2)
#        rank = NA
#        mean_log_score = "",
#        rank = factor(round(mean(as.numeric(rank))), levels=1:9)
    ) %>%
  ungroup() %>%
  group_by(prediction_target) %>%
  mutate(rank = rank(-1 * as.numeric(mean_log_score, 2))) %>%
  ungroup()

minimum_log_score <- res %>% group_by(prediction_target, model) %>%
    summarize(
        season="Lowest Log Score",
        mean_log_score = format(round(min(mean_log_score), 2), nsmall=2)
#        rank = NA
#        mean_log_score = "",
#        rank = factor(round(mean(as.numeric(rank))), levels=1:9)
    ) %>%
  ungroup() %>%
  group_by(prediction_target) %>%
  mutate(rank = rank(-1 * as.numeric(mean_log_score, 2))) %>%
  ungroup()

res_with_overall <- bind_rows(
  res %>%
    mutate(mean_log_score = format(round(mean_log_score,2), nsmall=2)),
  overall_rank,
  minimum_rank,
  overall_log_score,
  minimum_log_score)

ggplot(data = res_with_overall, aes(x = model, y = season)) +
  geom_tile(aes(fill = rank)) +
  geom_text(aes(label=mean_log_score)) +
  facet_wrap(~ prediction_target, ncol = 1) +
  scale_fill_gradient2("Model\nRank",
    breaks = 1:9,
#    labels = as.character(1:9),
    low = "#2166ac",
    mid = "#f7f7f7",
    high = "#b2182b",
    midpoint = 5) +
#    values = rev(c("#b2182b", "#d6604d", "#f4a582", "#fddbc7", "#f7f7f7", "#d1e5f0", "#92c5de", "#4393c3", "#2166ac"))) +
  xlab("Model") +
  ylab("Season") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
```


```{r perm_test_diff_from_medians, echo=FALSE, cache = TRUE}
awes_path <- find.package("awes")

all_models <- c("KDE", "KCDE", "SARIMA", "EW", "CW", "FW-wu", "FW-reg-w", "FW-reg-wu", "FW-reg-wui")

region_season_obs_quantities <- flu_data %>%
  select_(.dots = c("region", "season")) %>%
  distinct() %>%
  filter(season %in% paste0(2011:2015, "/", 2012:2016)) %>%
  mutate(
    observed_onset_week = NA,
    observed_peak_week = NA
  )

for(rs_row in seq_len(nrow(region_season_obs_quantities))) {
  temp <- get_observed_seasonal_quantities(
    data = flu_data[flu_data$region == region_season_obs_quantities$region[rs_row], , drop = FALSE],
    season = region_season_obs_quantities$season[rs_row],
    first_CDC_season_week = 10,
    last_CDC_season_week = 42,
    onset_baseline =
      get_onset_baseline(region = region_season_obs_quantities$region[rs_row],
        season = region_season_obs_quantities$season[rs_row]),
    incidence_var = "weighted_ili",
    incidence_bins = data.frame(
      lower = c(0, seq(from = 0.05, to = 12.95, by = 0.1)),
      upper = c(seq(from = 0.05, to = 12.95, by = 0.1), Inf)),
    incidence_bin_names = as.character(seq(from = 0, to = 13, by = 0.1))
  )

  region_season_obs_quantities$observed_onset_week[rs_row] <-
    temp$observed_onset_week
  region_season_obs_quantities$observed_peak_week[rs_row] <-
    temp$observed_peak_week[1]
}

region_season_obs_quantities$observed_onset_week[
  region_season_obs_quantities$observed_onset_week == "none"] <- 42
region_season_obs_quantities <- region_season_obs_quantities %>%
  transmute(
    region = ifelse(region == "X", "National", gsub(" ", "", region)),
    analysis_time_season = season,
    observed_onset_week = as.numeric(observed_onset_week),
    observed_peak_week = observed_peak_week
  )

all_models <- c("kde", "kcde", "sarima", "equal_weights", "em_stacking", "xgb_stacking_unregularized", "xgb_stacking_reg_w", "xgb_stacking_reg_wu", "xgb_stacking_reg_wui")
all_targets <- c("onset", "peak_week", "peak_inc")
preds <- assemble_predictions(
  preds_path = file.path(awes_path, "evaluation/test-predictions"),
  models = all_models,
  prediction_targets = all_targets,
  prediction_types = "log_score"
) %>%
  filter(analysis_time_season_week %in% 10:40) %>%
  gather_("prediction_target", "log_score",
    c("onset_log_score", "peak_week_log_score", "peak_inc_log_score")) %>%
  mutate(
    prediction_target = substr(prediction_target, 1, nchar(prediction_target) - 10),
    score = exp(log_score)
  )

preds$log_score[is.infinite(preds$log_score)] <- -15
preds <- preds %>%
  left_join(region_season_obs_quantities, by = c("region", "analysis_time_season")) %>%
  mutate(
    before_onset = (analysis_time_season_week < observed_onset_week),
    before_peak = (analysis_time_season_week < observed_peak_week))

preds$before_target_date <- ifelse(
  preds$prediction_target == "onset",
  c("on or after\ntarget date", "before\ntarget date")[preds$before_onset + 1],
  c("on or after\ntarget date", "before\ntarget date")[preds$before_peak + 1]
)

preds$model[preds$model == "kde"] <- "KDE"
preds$model[preds$model == "kcde"] <- "KCDE"
preds$model[preds$model == "sarima"] <- "SARIMA"
preds$model[preds$model == "equal_weights"] <- "EW"
preds$model[preds$model == "em_stacking"] <- "CW"
preds$model[preds$model == "xgb_stacking_unregularized"] <- "FW-wu"
preds$model[preds$model == "xgb_stacking_reg_w"] <- "FW-reg-w"
preds$model[preds$model == "xgb_stacking_reg_wu"] <- "FW-reg-wu"
preds$model[preds$model == "xgb_stacking_reg_wui"] <- "FW-reg-wui"
preds$model <- factor(preds$model,
  levels = c("KDE", "KCDE", "SARIMA",
    "EW", "CW", "FW-wu",
    "FW-reg-w", "FW-reg-wu", "FW-reg-wui"))

preds$prediction_target[preds$prediction_target == "onset"] <- "Onset Timing"
preds$prediction_target[preds$prediction_target == "peak_inc"] <- "Peak Incidence"
preds$prediction_target[preds$prediction_target == "peak_week"] <- "Peak Timing"
preds$prediction_target <- factor(preds$prediction_target,
  levels = c("Onset Timing", "Peak Timing", "Peak Incidence"))

preds <- preds %>%
  mutate(
    region = factor(region),
    analysis_time_season = factor(analysis_time_season)
  )


preds_wide <- preds %>%
#  dplyr::filter(before_target_date == "before\ntarget date") %>%
  dplyr::select(-score) %>%
  tidyr::spread(model, log_score)

registerDoMC(cores = 4)

all_models <- c("KDE", "KCDE", "SARIMA", "EW", "CW", "FW-wu", "FW-reg-w", "FW-reg-wu", "FW-reg-wui")
m_combos <- expand.grid(
  m1_ind = seq_along(all_models),
  m2_ind = seq_along(all_models)) %>%
  filter(m1_ind < m2_ind)
m_combos$m1 <- all_models[m_combos$m1_ind]
m_combos$m2 <- all_models[m_combos$m2_ind]


res <- mean(log_score ~ model + prediction_target + analysis_time_season + region,
  data = preds[preds$before_target_date == "before\ntarget date", ])
temp <- strsplit(names(res), ".", fixed = TRUE) %>%
  unlist() %>%
  matrix(ncol = 4, byrow = TRUE)
res <- cbind(temp, res) %>%
  as.data.frame(stringsAsFactors = FALSE) %>%
  `colnames<-`(c("model", "prediction_target", "season", "region", "mean_log_score")) %>%
  `rownames<-`(NULL) %>%
  group_by_(.dots = c("prediction_target", "season", "region")) %>%
  mutate(mean_log_score = as.numeric(mean_log_score),
    rank = rank(-1 * round(as.numeric(mean_log_score), 3)))

res$prediction_target <- factor(res$prediction_target,
  levels = c("Onset Timing", "Peak Timing", "Peak Incidence"))
res$model <- factor(res$model,
  levels = c("KDE", "KCDE", "SARIMA",
    "EW", "CW", "FW-wu",
    "FW-reg-w", "FW-reg-wu", "FW-reg-wui"))

res$region_season <- paste0(res$region, " - ", res$season)

median_per_target_season_region <- res %>%
  group_by(prediction_target, season, region) %>%
  summarize(median_mean_log_score = median(mean_log_score))

res2 <- res %>%
  left_join(median_per_target_season_region, by = c("prediction_target", "season", "region")) %>%
  mutate(diff_from_median = mean_log_score - median_mean_log_score)

all_models <- c("KDE", "KCDE", "SARIMA", "EW", "CW", "FW-wu", "FW-reg-w", "FW-reg-wu", "FW-reg-wui")
#all_models <- c("kde", "kcde", "sarima", "equal_weights", "em_stacking", "xgb_stacking_unregularized", "xgb_stacking_reg_w", "xgb_stacking_reg_wu", "xgb_stacking_reg_wui")

m_combos <- expand.grid(
  m1_ind = seq_along(all_models),
  m2_ind = seq_along(all_models)) %>%
  filter(m1_ind < m2_ind)
m_combos$m1 <- all_models[m_combos$m1_ind]
m_combos$m2 <- all_models[m_combos$m2_ind]

perm_test_res <- foreach(i = seq_len(nrow(m_combos))) %dopar% {
  model_pair <- m_combos[i, c("m1", "m2")]

  perm_res <- rbind.fill(lapply(seq_len(100), function(j) {
    perm_model_scores <- readRDS(
            file = paste0("~/Documents/research/epi/ensembles/adaptively-weighted-ensemble/inst/manuscript/score-permutations/perm_model_scores_season_diff_from_median_",
            model_pair[1],
            "_", model_pair[2],
            "_", j,
            ".rds"))

    lapply(perm_model_scores,
      function(comp) {
        temp <- apply(comp, 2, function(x) {quantile(x, 0.1)})
        return(data.frame(model_1_score = unname(temp[1]),
          model_2_score = unname(temp[2]),
          model_pair = paste(names(temp), collapse = "_"),
          statistic = "p10_diff_from_median"))
#        comp %>%
#          gather("model", "diff_from_median", colnames(comp)) %>%
#          group_by(model) %>%
#          summarize(p_lt_median = mean(diff_from_median < 0),
#            mean_diff_from_median = mean(diff_from_median),
#            min_diff_from_median = min(diff_from_median),
#            p10_diff_from_median = quantile(diff_from_median, 0.1)) %>%
#          gather("statistic", "value", colnames(.)[2:5]) %>%
#          mutate(model_pair = paste(colnames(comp), collapse = "_"))
      }) %>%
      rbind.fill()
  }))
}

realized_res <- res2 %>%
  group_by(model) %>%
  summarize(p_lt_median = mean(diff_from_median < 0),
    mean_diff_from_median = mean(diff_from_median),
    min_diff_from_median = min(diff_from_median),
    p10_diff_from_median = quantile(diff_from_median, 0.1)) %>%
  gather("statistic", "value", p_lt_median, mean_diff_from_median, min_diff_from_median, p10_diff_from_median) %>%
  mutate(model = as.character(model))

perm_test_c <- rbind.fill(perm_test_res)

perm_test_summaries <- perm_test_c %>%
  dplyr::mutate(
    model_pair = as.character(model_pair),
    statistic = as.character(statistic),
    perm_abs_diff = abs(model_1_score - model_2_score)) %>%
#  dplyr::mutate(perm_ind = rep(seq_len(nrow(perm_test_c)/4), each = 4),
#    model = rep(paste0("model_", c(1, 2), "_score"), times = nrow(perm_test_c)/2)) %>%
#  tidyr::spread(model, value) %>%
#  dplyr::mutate(perm_abs_diff = abs(model_1_score - model_2_score)) %>%
  dplyr::mutate(model_1 = sapply(strsplit(model_pair, "_"), function(comp) {comp[[1]]}),
    model_2 = sapply(strsplit(model_pair, "_"), function(comp) {comp[[2]]})
    ) %>%
  dplyr::left_join(realized_res, by = c("model_1" = "model", "statistic")) %>%
  dplyr::mutate(model_1_score_true = value) %>%
  dplyr::select(-value) %>%
  dplyr::left_join(realized_res, by = c("model_2" = "model", "statistic")) %>%
  dplyr::mutate(model_2_score_true = value) %>%
  dplyr::select(-value) %>%
  dplyr::mutate(realized_diff = model_1_score_true - model_2_score_true,
    realized_abs_diff = abs(model_1_score_true - model_2_score_true)) %>%
  dplyr::group_by(statistic, model_pair, model_1, model_2, realized_diff) %>%
  dplyr::summarize(abs_diff_pval = mean(perm_abs_diff >= realized_abs_diff))

realized_res <- mutate(realized_res, model = factor(model, levels = all_models))
```

```{r min_diff_from_median_perm_test_plot, echo = FALSE, fig.height=8.5, fig.cap="\\label{fig:pvals}For each combination of 3 prediction targets, 11 regions, and 5 test phase seasons, we calculated the difference in mean log scores between each method and the method with median performance for that target, region, and season.  Panel A presents the minimum difference from the median model for each method across all combinations of target, region, and season.  Larger values of this quantity indicate that the given model has better worst-case performance.  Panel B displays the difference in this measure of worst-case performance for each pair of models.  Positive values indicate that the model on the vertical axis had better worst-case performance than the model on the horizontal axis.  A permutation test was used to obtain approximate p-values for these differences (see supplement for details).  For reference, a Bonferroni correction at a familywise significance level of 0.05 for all pairwise comparisons leads to a significance cutoff of approximately 0.0014."}
stat_ind <- 1
stat_val <- unique(perm_test_summaries$statistic)[stat_ind]

realized_res <- res2 %>%
  group_by(model) %>%
  summarize(p_lt_median = mean(diff_from_median < 0),
    mean_diff_from_median = mean(diff_from_median),
    min_diff_from_median = min(diff_from_median),
    p10_diff_from_median = quantile(diff_from_median, 0.1),
    min_mean_log_score = min(mean_log_score)) %>%
  gather("statistic", "value", p_lt_median, mean_diff_from_median, min_diff_from_median, p10_diff_from_median, min_mean_log_score)

p_res <- ggplot(
    data = realized_res %>%
      filter(statistic == stat_val) %>%
      mutate(y = 0)) +
  geom_tile(aes(x = model, y = y, fill = value)) +
  geom_text(aes(x = model, y = y, label=format(round(value, 3), nsmall = 3)),
    size = 3) +
  scale_fill_gradient2("",
    low = "#b2182b",
    mid = "#f7f7f7",
    high = "#2166ac",
    midpoint = 0) +
  xlab("Model") +
  ylab("") +
  ggtitle("A: Minimum Difference in Log Scores from Median Method") +
#  ggtitle(stat_val) +
  theme_bw() +
  theme(axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
    plot.margin = unit(c(5.5, 5.5, 5.5, 55.5), "pt"))

perm_test_for_plot <- perm_test_summaries %>% filter(statistic == stat_val) %>%
  ungroup() %>%
  mutate(
    model_1 = factor(model_1, levels = all_models),
    model_2 = factor(model_2, levels = all_models)
    )
perm_test_for_plot2 <- perm_test_for_plot
perm_test_for_plot2$model_1 <- perm_test_for_plot$model_2
perm_test_for_plot2$model_2 <- perm_test_for_plot$model_1
perm_test_for_plot2$realized_diff <- -1 * perm_test_for_plot$realized_diff
perm_test_for_plot_c <- rbind(perm_test_for_plot, perm_test_for_plot2)

p_pvals <- ggplot(data = perm_test_for_plot_c) +
  geom_tile(aes(x = model_2, y = model_1, fill = realized_diff)) +
  geom_text(aes(x = model_2, y = model_1, label=paste0(
    format(round(realized_diff, 3), nsmall = 3),
    "\n(",
    format(round(abs_diff_pval, 3), nsmall = 3),
    ")")),
    size = 3) +
#  geom_text(aes(x = m1, y = m2, label=paste0(pval_diff)),
#    size = 3) +
  scale_fill_gradient2("",
#    breaks = 1:9,
#    labels = as.character(1:9),
    low = "#b2182b",
    mid = "#f7f7f7",
    high = "#2166ac",
    midpoint = 0) +
  xlab("Model") +
  ylab("Model") +
  ggtitle("B: Pairwise Differences in\nMinimum Difference in Log Scores from Median Method") +
#  ggtitle(stat_val) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
    panel.grid.minor=element_blank(),
    panel.grid.major=element_blank())

grid.newpage()
blank_height <- 0
rel_height_lower <- 1.35
pushViewport(viewport(layout =
    grid.layout(nrow = 2, ncol = 1,
      heights = unit(
        c(1, 3),
        c("null", "null")),
      widths = unit(c(1), c("null")))))
print(p_res, vp = viewport(layout.pos.row = 1, layout.pos.col = 1))
print(p_pvals, vp = viewport(layout.pos.row = 2, layout.pos.col = 1))
#pushViewport(viewport(layout =
#    grid.layout(nrow = 2, ncol = 1,
#      heights = unit(
#        c(1, 3),
#        c("null", "null")),
#      widths = unit(c(1), c("null")))))
#print(p_res, vp = viewport(layout.pos.row = 1, layout.pos.col = 1))
#print(p_pvals, vp = viewport(layout.pos.row = 2, layout.pos.col = 1))
```
